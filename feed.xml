<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://arrow.apache.org/feed.xml" rel="self" type="application/atom+xml" /><link href="https://arrow.apache.org/" rel="alternate" type="text/html" /><updated>2021-11-18T19:24:28-05:00</updated><id>https://arrow.apache.org/feed.xml</id><title type="html">Apache Arrow</title><subtitle>Apache Arrow is a cross-language development platform for in-memory data. It specifies a standardized language-independent columnar memory format for flat and hierarchical data, organized for efficient analytic operations on modern hardware. It also provides computational libraries and zero-copy streaming messaging and interprocess communication. Languages currently supported include C, C++, C#, Go, Java, JavaScript, MATLAB, Python, R, Ruby, and Rust.</subtitle><entry><title type="html">Apache Arrow Rust 6.0.0 Release</title><link href="https://arrow.apache.org/blog/2021/11/09/6.0.0-rs-release/" rel="alternate" type="text/html" title="Apache Arrow Rust 6.0.0 Release" /><published>2021-11-09T00:00:00-05:00</published><updated>2021-11-09T00:00:00-05:00</updated><id>https://arrow.apache.org/blog/2021/11/09/6.0.0-rs-release</id><content type="html" xml:base="https://arrow.apache.org/blog/2021/11/09/6.0.0-rs-release/">&lt;!--

--&gt;

&lt;p&gt;We recently released the 6.0.0 Rust version of Apache Arrow, which 
coincides with the &lt;a href=&quot;/6.0.0.html&quot;&gt;Arrow 6.0.0 release&lt;/a&gt;. This 
post highlights some of the improvements in the Rust implementation. The full changelog can be 
found &lt;a href=&quot;https://github.com/apache/arrow-rs/blob/6.0.0/CHANGELOG.md&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;!--
(arrow_dev) bkmgit@Linux:~/arrow-rs$ git log --pretty=oneline 5.0.0..6.0.0 | wc -l
     99
(arrow_dev) bkmgit@Linux:~/arrow-rs$ git shortlog -sn 5.0.0..6.0.0 | wc -l
     35
--&gt;

&lt;p&gt;The Rust Arrow implementation would not be possible without the wonderful work and support of our community, and 
the 6.0.0 release is no exception. It includes 99 commits from 35 individual contributors, many of them with 
their first contribution. Thank you all very much.&lt;/p&gt;

&lt;h1 id=&quot;arrow&quot;&gt;Arrow&lt;/h1&gt;

&lt;p&gt;Highlighted features and changes between release 5.0.0 and this release are:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;New MapArray support&lt;/li&gt;
  &lt;li&gt;Add optimized filter kernel for regular expression matching&lt;/li&gt;
  &lt;li&gt;Implement &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sort()&lt;/code&gt; for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BinaryArray&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Replace &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ArrayData::new()&lt;/code&gt; with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ArrayData::try_new()&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;unsafe ArrayData::new_unchecked&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Sorting should require less memory and be faster&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Of course, this release also contains bug fixes, performance improvements, and improved documentation examples. For the full list of changes, 
please consult the &lt;a href=&quot;https://github.com/apache/arrow-rs/blob/6.0.0/CHANGELOG.md&quot;&gt;changelog&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;more-frequent-releases&quot;&gt;More Frequent Releases&lt;/h1&gt;
&lt;p&gt;Arrow releases major versions every three months. The Rust implementation follows this 
major release cycle, and additionally releases minor version updates approximately every other week
to speed the flow of new features and fixes.&lt;/p&gt;

&lt;p&gt;You can always find the latest releases on crates.io: &lt;a href=&quot;https://crates.io/crates/arrow&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arrow&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;https://crates.io/crates/parquet&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parquet&lt;/code&gt;&lt;/a&gt;, 
&lt;a href=&quot;https://crates.io/crates/arrow-flight&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arrow-flight&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;https://crates.io/crates/parquet-derive&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parquet-derive&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;datafusion--ballista&quot;&gt;DataFusion &amp;amp; Ballista&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.rs/datafusion/&quot;&gt;DataFusion&lt;/a&gt; is an in-memory query engine with DataFrame and SQL APIs, built on top of Arrow. 
Ballista is a distributed compute platform. These projects are now in their &lt;a href=&quot;https://github.com/apache/arrow-datafusion&quot;&gt;own repository&lt;/a&gt;, 
and are no longer released in lock-step with Arrow.&lt;/p&gt;

&lt;h1 id=&quot;highlighted-functionality&quot;&gt;Highlighted Functionality&lt;/h1&gt;
&lt;p&gt;The memory required to do sorting has been improve by the pull request resolving issue &lt;a href=&quot;https://github.com/apache/arrow-rs/issues/553&quot;&gt;553&lt;/a&gt;. 
A demonstration for how to sort follows.&lt;/p&gt;
&lt;div class=&quot;language-rust highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;extern&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;crate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;use&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nn&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Int32Array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ArrayRef&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;use&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nn&quot;&gt;sync&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;Arc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;use&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nn&quot;&gt;compute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ArrayRef&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;Arc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nn&quot;&gt;Int32Array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;vec!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;23&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]));&lt;/span&gt;
    &lt;span class=&quot;nd&quot;&gt;println!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{:?}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sorted_array&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;nd&quot;&gt;println!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{:?}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sorted_array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;For further examples, see the &lt;a href=&quot;https://github.com/apache/arrow-rs/blob/master/arrow/src/compute/kernels/sort.rs&quot;&gt;source code&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;roadmap-for-700-and-beyond&quot;&gt;Roadmap for 7.0.0 and Beyond&lt;/h1&gt;
&lt;p&gt;Here are some of the initiatives that contributors are currently working on for future releases:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Validate arguments to ArrayData::new and null bit buffer and buffers&lt;/li&gt;
  &lt;li&gt;add ilike comparitor&lt;/li&gt;
  &lt;li&gt;refactor regexp_is_match_utf8_scalar&lt;/li&gt;
  &lt;li&gt;add support for float 16&lt;/li&gt;
  &lt;li&gt;Updated &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UnionArray&lt;/code&gt; support to follow the latest arrow spec&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;contributors-to-600&quot;&gt;Contributors to 6.0.0:&lt;/h1&gt;
&lt;p&gt;Again, thank you to all the contributors for this release. Here is the raw git listing:&lt;/p&gt;

&lt;!--
(arrow_dev) bkmgit@Linux:~/arrow-rs$ git shortlog -sn 5.0.0..6.0.0
.. list below ..
--&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    23  Andrew Lamb
     8  Ben Chambers
     8  Navin
     7  Jiayu Liu
     5  Wakahisa
     4  Ruihang Xia
     3  Daniël Heres
     3  Matthew Turner
     3  Sumit
     2  Boaz
     2  Chojan Shang
     2  Ilya Biryukov
     2  Krisztián Szűcs
     2  Markus Westerlind
     2  Roee Shlomo
     2  Sergii Mikhtoniuk
     2  Wang Fenjin
     2  baishen
     1  Carol (Nichols || Goulding)
     1  Christian Williams
     1  Felix Yan
     1  Jorge Leitao
     1  Kornelijus Survila
     1  Matthew Zeitlin
     1  Mike Seddon
     1  Mykhailo Osypov
     1  Neal Richardson
     1  Pete Koomen
     1  QP Hou
     1  Richard
     1  Xavier Lange
     1  Yuan Zhou
     1  aiglematth
     1  mathiaspeters-sig
     1  msalib
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;how-to-get-involved&quot;&gt;How to Get Involved&lt;/h1&gt;
&lt;p&gt;If you are interested in contributing to the Rust implementation of Apache Arrow, we would love to have you! You can help by 
trying out Arrow on some of your own data and projects and filing bug reports and helping to improve the documentation, or 
contribute to the documentation, tests or code. A list of open issues suitable for beginners is 
&lt;a href=&quot;https://github.com/apache/arrow-rs/labels/good%20first%20issue&quot;&gt;here&lt;/a&gt; and the full list is
&lt;a href=&quot;https://github.com/apache/arrow-rs/issues&quot;&gt;here&lt;/a&gt;&lt;/p&gt;</content><author><name>pmc</name></author><category term="release" /><summary type="html">We recently released the 6.0.0 Rust version of Apache Arrow, which coincides with the Arrow 6.0.0 release. This post highlights some of the improvements in the Rust implementation. The full changelog can be found here. The Rust Arrow implementation would not be possible without the wonderful work and support of our community, and the 6.0.0 release is no exception. It includes 99 commits from 35 individual contributors, many of them with their first contribution. Thank you all very much. Arrow Highlighted features and changes between release 5.0.0 and this release are: New MapArray support Add optimized filter kernel for regular expression matching Implement sort() for BinaryArray Replace ArrayData::new() with ArrayData::try_new() and unsafe ArrayData::new_unchecked Sorting should require less memory and be faster Of course, this release also contains bug fixes, performance improvements, and improved documentation examples. For the full list of changes, please consult the changelog. More Frequent Releases Arrow releases major versions every three months. The Rust implementation follows this major release cycle, and additionally releases minor version updates approximately every other week to speed the flow of new features and fixes. You can always find the latest releases on crates.io: arrow, parquet, arrow-flight, and parquet-derive. DataFusion &amp;amp; Ballista DataFusion is an in-memory query engine with DataFrame and SQL APIs, built on top of Arrow. Ballista is a distributed compute platform. These projects are now in their own repository, and are no longer released in lock-step with Arrow. Highlighted Functionality The memory required to do sorting has been improve by the pull request resolving issue 553. A demonstration for how to sort follows. extern crate arrow; use arrow::array::{ Int32Array, ArrayRef, }; use std::sync::Arc; use arrow::compute::sort; fn main() { let array: ArrayRef = Arc::new(Int32Array::from(vec![5, 4, 23, 1, 20, 2])); println!(&quot;{:?}&quot;, array); let sorted_array = sort(&amp;amp;array, None).unwrap(); println!(&quot;{:?}&quot;, sorted_array); } For further examples, see the source code. Roadmap for 7.0.0 and Beyond Here are some of the initiatives that contributors are currently working on for future releases: Validate arguments to ArrayData::new and null bit buffer and buffers add ilike comparitor refactor regexp_is_match_utf8_scalar add support for float 16 Updated UnionArray support to follow the latest arrow spec Contributors to 6.0.0: Again, thank you to all the contributors for this release. Here is the raw git listing: 23 Andrew Lamb 8 Ben Chambers 8 Navin 7 Jiayu Liu 5 Wakahisa 4 Ruihang Xia 3 Daniël Heres 3 Matthew Turner 3 Sumit 2 Boaz 2 Chojan Shang 2 Ilya Biryukov 2 Krisztián Szűcs 2 Markus Westerlind 2 Roee Shlomo 2 Sergii Mikhtoniuk 2 Wang Fenjin 2 baishen 1 Carol (Nichols || Goulding) 1 Christian Williams 1 Felix Yan 1 Jorge Leitao 1 Kornelijus Survila 1 Matthew Zeitlin 1 Mike Seddon 1 Mykhailo Osypov 1 Neal Richardson 1 Pete Koomen 1 QP Hou 1 Richard 1 Xavier Lange 1 Yuan Zhou 1 aiglematth 1 mathiaspeters-sig 1 msalib How to Get Involved If you are interested in contributing to the Rust implementation of Apache Arrow, we would love to have you! You can help by trying out Arrow on some of your own data and projects and filing bug reports and helping to improve the documentation, or contribute to the documentation, tests or code. A list of open issues suitable for beginners is here and the full list is here</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arrow.apache.org/img/arrow.png" /><media:content medium="image" url="https://arrow.apache.org/img/arrow.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow R 6.0.0 Release</title><link href="https://arrow.apache.org/blog/2021/11/08/r-6.0.0/" rel="alternate" type="text/html" title="Apache Arrow R 6.0.0 Release" /><published>2021-11-08T00:00:00-05:00</published><updated>2021-11-08T00:00:00-05:00</updated><id>https://arrow.apache.org/blog/2021/11/08/r-6.0.0</id><content type="html" xml:base="https://arrow.apache.org/blog/2021/11/08/r-6.0.0/">&lt;!--

--&gt;

&lt;p&gt;We are excited to announce the recent release of version 6.0.0 of the Arrow R package on &lt;a href=&quot;https://cran.r-project.org/package=arrow&quot;&gt;CRAN&lt;/a&gt;. While we usually don’t write a dedicated release blog post for the R package, this one is special. There are a number of major new features in this version, some of which we’ve been building up to for several years.&lt;/p&gt;

&lt;h1 id=&quot;more-dplyr-support&quot;&gt;More dplyr support&lt;/h1&gt;

&lt;p&gt;In version 0.16.0 (February 2020), we released the first version of the Dataset feature, which allowed you to query multi-file datasets using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dplyr::select()&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filter()&lt;/code&gt;. These tools allowed you to find a slice of data in a large dataset that may not fit into memory and pull it into R for further analysis. In version 4.0.0 earlier this year, we added support for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mutate()&lt;/code&gt; and a number of other dplyr verbs, and all year we’ve been adding hundreds of functions you can use to transform and filter data in Datasets. However, to aggregate, you’d still need to pull the data into R.&lt;/p&gt;

&lt;h2 id=&quot;grouped-aggregation&quot;&gt;Grouped aggregation&lt;/h2&gt;

&lt;p&gt;With &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arrow&lt;/code&gt; 6.0.0, you can now &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;summarise()&lt;/code&gt; on Arrow data, both with or without &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;group_by()&lt;/code&gt;. These are supported both with in-memory Arrow tables as well as across partitioned datasets. Most common aggregation functions are supported: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n()&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n_distinct()&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min(),&lt;/code&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max()&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sum()&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mean()&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;var()&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sd()&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;any()&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;all()&lt;/code&gt;. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;median()&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quantile()&lt;/code&gt; with one probability are also supported and currently return approximate results using the t-digest algorithm.&lt;/p&gt;

&lt;p&gt;As usual, Arrow will read and process data in chunks and in parallel when possible to produce results much faster than one could by loading it all into memory then processing. This allows for operations that wouldn’t fit into memory on a single machine. For example, using the 1.5-billion row NYC Taxi dataset we use for examples in the &lt;a href=&quot;https://arrow.apache.org/docs/r/articles/dataset.html&quot;&gt;package vignette&lt;/a&gt;, we can aggregate over the whole dataset even on a laptop:&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;open_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;nyc-taxi&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;partitioning&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;year&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;month&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;passenger_count&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;passenger_count&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grepl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;csh&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;payment_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ignore.case&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;passenger_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summarize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_amount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;na.rm&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; # A tibble: 5 × 3&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;   passenger_count   avg     count&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;             &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;     &amp;lt;int&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; 1               1  11.1 257738064&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; 2               2  12.1  58824482&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; 3               5  11.4  26056438&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; 4               3  12.0  18852606&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; 5               4  12.3  10081632&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;joins&quot;&gt;Joins&lt;/h2&gt;

&lt;p&gt;In addition to aggregation, Arrow also supports all of dplyr’s mutating joins (inner, left, right, and full) and filtering joins (semi and anti).&lt;/p&gt;

&lt;p&gt;Suppose I want to get a table of all the flights from JFK to Las Vegas Airport on
9th October 2013, with the full name of the airline included.&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;arrow_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nycflights13&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2013&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;day&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;JFK&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dest&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;LAS&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dep_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left_join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nycflights13&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;airlines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; # A tibble: 12 × 4&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;    dep_time arr_time carrier name&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;       &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;  1      637      853 B6      JetBlue Airways&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;  2      648      912 AA      American Airlines Inc.&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;  3      812     1029 DL      Delta Air Lines Inc.&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;  4      945     1206 VX      Virgin America&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;  5      955     1219 B6      JetBlue Airways&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;  6     1018     1231 DL      Delta Air Lines Inc.&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;  7     1120     1338 B6      JetBlue Airways&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;  8     1451     1705 DL      Delta Air Lines Inc.&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;  9     1656     1915 AA      American Airlines Inc.&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; 10     1755     2001 DL      Delta Air Lines Inc.&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; 11     1827     2049 B6      JetBlue Airways&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; 12     1917     2126 DL      Delta Air Lines Inc.&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In this example, we’re working on an in-memory table, so you wouldn’t need &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arrow&lt;/code&gt; to do this–but the same code would work on a larger-than-memory dataset backed by thousands of Parquet files.&lt;/p&gt;

&lt;h2 id=&quot;under-the-hood&quot;&gt;Under the hood&lt;/h2&gt;

&lt;p&gt;To support these features, we’ve made some internal changes to how queries are built up and–importantly–when they are evaluated. As a result, there are some changes in behavior compared to past versions of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arrow&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;First, calls to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;summarise()&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;head()&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tail()&lt;/code&gt; no longer eagerly evaluate: this means you need to call either &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;compute()&lt;/code&gt; (to evaluate it and produce an Arrow Table) or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;collect()&lt;/code&gt; (to evaluate and pull the Table into an R &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;data.frame&lt;/code&gt;) to see the results.&lt;/p&gt;

&lt;p&gt;Second, the order of rows in a dataset query is no longer determinisitic due to the way the parallelization of work happens in the C++ library. This means that you can’t assume that the results of a query will be in the same order as the rows of data in the files on disk. If you do need a stable sort order, call &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arrange()&lt;/code&gt; to specify ordering.&lt;/p&gt;

&lt;p&gt;While these changes are a break from past &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arrow&lt;/code&gt; behavior, they are consistent with many &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dbplyr&lt;/code&gt; backends and are needed to allow queries to scale beyond data-frame workflows that can fit into memory.&lt;/p&gt;

&lt;h1 id=&quot;integration-with-duckdb&quot;&gt;Integration with DuckDB&lt;/h1&gt;

&lt;p&gt;The Arrow engine is not the only new way to query Arrow Datasets in this release. If you have the &lt;a href=&quot;https://cran.r-project.org/package=duckdb&quot;&gt;duckdb&lt;/a&gt; package installed, you can hand off an Arrow Dataset or query object to &lt;a href=&quot;https://duckdb.org/&quot;&gt;DuckDB&lt;/a&gt; for further querying using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;to_duckdb()&lt;/code&gt; function. This allows you to use duckdb’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dbplyr&lt;/code&gt; methods, as well as its SQL interface, to aggregate data. DuckDB supports filter pushdown, so you can take advantage of Arrow Datasets and Arrow-based optimizations even within a DuckDB SQL query with a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;where&lt;/code&gt; clause. Filtering and column projection specified before the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;to_duckdb()&lt;/code&gt; call in a pipeline is evaluated in Arrow; this can be helpful in some circumstances like complicated dbplyr pipelines.  You can also hand off DuckDB data (or the result of a query) to arrow with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;to_arrow()&lt;/code&gt; call.&lt;/p&gt;

&lt;p&gt;In the example below, we are looking at flights between NYC and Chicago, and want to avoid the worst-of-the-worst delays. To do this, we can use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;percent_rank()&lt;/code&gt;; however that requires a window function which isn’t yet available in Arrow, so let’s try sending the data to DuckDB to do that, then pull it back into Arrow:&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warn.conflicts&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dplyr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warn.conflicts&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flights_filtered&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nycflights13&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr_delay&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# arriving early doesn&apos;t matter, so call negative delays 0&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mutate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr_delay&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr_delay&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# for each carrier-origin-dest, take the worst 5% of delays&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mutate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr_delay_rank&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;percent_rank&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr_delay&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr_delay_rank&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flights_filtered&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; # Source:   lazy query [?? x 5]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; # Database: duckdb_connection&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; # Groups:   carrier, origin, dest&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;   carrier origin dest  arr_delay arr_delay_rank&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt;          &amp;lt;dbl&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; 1 9E      JFK    RIC         119          0.952&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; 2 9E      JFK    RIC         125          0.956&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; 3 9E      JFK    RIC         137          0.960&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; 4 9E      JFK    RIC         137          0.960&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; 5 9E      JFK    RIC         158          0.968&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; 6 9E      JFK    RIC         163          0.972&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now we have all of the flights filtered to those that are the worst-of-the-worst, and stored as a dbplyr lazy &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tbl&lt;/code&gt; with our DuckDB connection. This is an example of using Arrow -&amp;gt; DuckDB.&lt;/p&gt;

&lt;p&gt;But we can do more: we can then bring that data back into Arrow just as easily. For the rest of our analysis, we pick up where we left off with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tbl&lt;/code&gt; referring to the DuckDB query:&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# pull data back into arrow to complete analysis&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flights_filtered&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# now summarise to get mean/min&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summarise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr_delay_mean&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr_delay&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr_delay_min&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr_delay&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_flights&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dest&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%in%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;ORD&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;MDW&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr_delay_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; # A tibble: 10 × 6&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; # Groups:   carrier, origin [10]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;    carrier origin dest  arr_delay_mean arr_delay_min num_flights&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;       &amp;lt;int&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;  1 MQ      EWR    ORD             190.           103         113&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;  2 9E      JFK    ORD             185.           134          52&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;  3 UA      LGA    ORD             179.           101         157&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;  4 WN      LGA    MDW             178.           107         103&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;  5 AA      JFK    ORD             178.           133          19&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;  6 B6      JFK    ORD             174.           129          46&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;  7 WN      EWR    MDW             167.           107         103&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;  8 UA      EWR    ORD             149.            87         189&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;  9 AA      LGA    ORD             135.            78         280&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; 10 EV      EWR    ORD              35             35           1&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And just like that, we’ve passed data back and forth between Arrow and DuckDB without having to write a single file to disk!&lt;/p&gt;

&lt;h1 id=&quot;expanded-use-of-altrep&quot;&gt;Expanded use of ALTREP&lt;/h1&gt;

&lt;p&gt;We are continuing our use of R’s &lt;a href=&quot;https://svn.r-project.org/R/branches/ALTREP/ALTREP.html&quot;&gt;ALTREP&lt;/a&gt; where possible. In 5.0.0 there were a limited set of circumstances that took advantage of ALTREP, but in 6.0.0 we have expanded types to include strings, as well as vectors with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NA&lt;/code&gt;s.&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;microbenchmark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10000000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;letters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;NA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10000000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;with_altrep&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow.use_altrep&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as.data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;without_altrep&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow.use_altrep&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as.data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;microbenchmark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;without_altrep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;with_altrep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt; Unit: milliseconds&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;                 expr      min        lq      mean    median        uq      max neval&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;  without_altrep(tbl) 191.0788 213.82235 249.65076 225.52120 244.26977 512.1652   100&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#&amp;gt;     with_altrep(tbl)  48.7152  50.97269  65.56832  52.93795  55.24505 338.4602   100&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;airgapped-installation-on-linux&quot;&gt;Airgapped installation on Linux&lt;/h1&gt;

&lt;p&gt;With every release, we continue to improve the installation experience on Linux. Unlike macOS and Windows, CRAN does not host binary packages for Linux, and unless you’re using a service like RStudio Package Manger that hosts binaries, you have to build &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arrow&lt;/code&gt; from source. Because Arrow involves a large C++ project, this can be slow and sensitive to differences in build environments. To ensure a reliable installation experience, we work hard to test on a wide range of platforms and configurations and eagerly seek to simplify the process so that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;install.packages(&quot;arrow&quot;)&lt;/code&gt; just works and you don’t have to think about it.&lt;/p&gt;

&lt;p&gt;A big improvement in 6.0.0 is that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arrow&lt;/code&gt; can now install in a fully offline mode. The R package now includes the C++ source, so it does not need to be downloaded at build time. This does not include optional dependencies like compression libraries, the AWS SDK for accessing data in S3, and more. For folks who need to install Arrow on an airgapped server with all of those features, we have included a helper function to download and assemble a “fat” pacakge that contains everything that would be downloaded lazily at build time.
The function &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;create_package_with_all_dependencies()&lt;/code&gt; can be run from a computer that does have access to the internet, and creates a fat-source package which can then be transferred and installed on a server without connectivity. This helper is also available on GitHub without installing the arrow package. For more installation &lt;a href=&quot;https://arrow.apache.org/docs/r/articles/install.html#offline-installation&quot;&gt;see the docs&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Another installation change is that we’ve changed the source build to fail cleanly if the C++ library is not found or cannot be built. Previously, if the C++ library failed to build, you would get a successful R package installation, but the package wouldn’t do anything useful, it would just tell you to reinstall. This was helpful back in the early days of the package when we weren’t confident it would build everywhere that CRAN checked, but we now have much more experience (and extensive testing). In recent months this failure mode caused more confusion than it was worth, and it led many people to think that after you install arrow, you always have to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;install_arrow()&lt;/code&gt; again.&lt;/p&gt;

&lt;h1 id=&quot;thanks&quot;&gt;Thanks&lt;/h1&gt;

&lt;p&gt;This is a significant milestone for Arrow, and the R package specifically, and there is much gratitude to go around. In the 6.0.0 release, there were 77 individuals who contributed to Arrow, many of whom did the heavy lifting in the C++ library to make the new dataset query features a reality. Specifically in the R package, we wanted to acknowledge Phillip Cloud, Dewey Dunnington, Dragoș Moldovan-Grünfeld, Matt Peterson, and Percy Camilo Triveño Aucahuasi for their
their first contributions to the R package. And a special thanks goes to Karl Dunkle Werner for the hard work on the offline package build!&lt;/p&gt;

&lt;p&gt;We also want to thank you in advance for your help. For this release of the Arrow query engine, we’ve focused our effort on getting the core functionality implemented. (In fact, this first release is something of an R-exclusive: bindings for these features haven’t yet been added to pyarrow, the Python Arrow library!) By focusing on the essentials, it means that there are a number of performance optimizations we plan to do but didn’t have time for in this release–and there are surely more issues to improve that we don’t yet know. We are eager for your feedback: please &lt;a href=&quot;https://issues.apache.org/jira/browse/ARROW&quot;&gt;let us know&lt;/a&gt; of any issues you encounter so that we can improve these for our next release.&lt;/p&gt;</content><author><name>Nic Crane, Jonathan Keane, Neal Richardson</name></author><category term="release" /><summary type="html">We are excited to announce the recent release of version 6.0.0 of the Arrow R package on CRAN. While we usually don’t write a dedicated release blog post for the R package, this one is special. There are a number of major new features in this version, some of which we’ve been building up to for several years. More dplyr support In version 0.16.0 (February 2020), we released the first version of the Dataset feature, which allowed you to query multi-file datasets using dplyr::select() and filter(). These tools allowed you to find a slice of data in a large dataset that may not fit into memory and pull it into R for further analysis. In version 4.0.0 earlier this year, we added support for mutate() and a number of other dplyr verbs, and all year we’ve been adding hundreds of functions you can use to transform and filter data in Datasets. However, to aggregate, you’d still need to pull the data into R. Grouped aggregation With arrow 6.0.0, you can now summarise() on Arrow data, both with or without group_by(). These are supported both with in-memory Arrow tables as well as across partitioned datasets. Most common aggregation functions are supported: n(), n_distinct(), min(), max(), sum(), mean(), var(), sd(), any(), and all(). median() and quantile() with one probability are also supported and currently return approximate results using the t-digest algorithm. As usual, Arrow will read and process data in chunks and in parallel when possible to produce results much faster than one could by loading it all into memory then processing. This allows for operations that wouldn’t fit into memory on a single machine. For example, using the 1.5-billion row NYC Taxi dataset we use for examples in the package vignette, we can aggregate over the whole dataset even on a laptop: ds &amp;lt;- open_dataset(&quot;nyc-taxi&quot;, partitioning = c(&quot;year&quot;, &quot;month&quot;)) ds %&amp;gt;% filter( passenger_count &amp;gt; 0, passenger_count &amp;lt; 6, grepl(&quot;csh&quot;, payment_type, ignore.case = TRUE) ) %&amp;gt;% group_by(passenger_count) %&amp;gt;% summarize( avg = mean(total_amount, na.rm = TRUE), count = n() ) %&amp;gt;% arrange(desc(count)) %&amp;gt;% collect() #&amp;gt; # A tibble: 5 × 3 #&amp;gt; passenger_count avg count #&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; #&amp;gt; 1 1 11.1 257738064 #&amp;gt; 2 2 12.1 58824482 #&amp;gt; 3 5 11.4 26056438 #&amp;gt; 4 3 12.0 18852606 #&amp;gt; 5 4 12.3 10081632 Joins In addition to aggregation, Arrow also supports all of dplyr’s mutating joins (inner, left, right, and full) and filtering joins (semi and anti). Suppose I want to get a table of all the flights from JFK to Las Vegas Airport on 9th October 2013, with the full name of the airline included. arrow_table(nycflights13::flights) %&amp;gt;% filter( year == 2013, month == 10, day == 9, origin == &quot;JFK&quot;, dest == &quot;LAS&quot; ) %&amp;gt;% select(dep_time, arr_time, carrier) %&amp;gt;% left_join( arrow_table(nycflights13::airlines) ) %&amp;gt;% collect() #&amp;gt; # A tibble: 12 × 4 #&amp;gt; dep_time arr_time carrier name #&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; #&amp;gt; 1 637 853 B6 JetBlue Airways #&amp;gt; 2 648 912 AA American Airlines Inc. #&amp;gt; 3 812 1029 DL Delta Air Lines Inc. #&amp;gt; 4 945 1206 VX Virgin America #&amp;gt; 5 955 1219 B6 JetBlue Airways #&amp;gt; 6 1018 1231 DL Delta Air Lines Inc. #&amp;gt; 7 1120 1338 B6 JetBlue Airways #&amp;gt; 8 1451 1705 DL Delta Air Lines Inc. #&amp;gt; 9 1656 1915 AA American Airlines Inc. #&amp;gt; 10 1755 2001 DL Delta Air Lines Inc. #&amp;gt; 11 1827 2049 B6 JetBlue Airways #&amp;gt; 12 1917 2126 DL Delta Air Lines Inc. In this example, we’re working on an in-memory table, so you wouldn’t need arrow to do this–but the same code would work on a larger-than-memory dataset backed by thousands of Parquet files. Under the hood To support these features, we’ve made some internal changes to how queries are built up and–importantly–when they are evaluated. As a result, there are some changes in behavior compared to past versions of arrow. First, calls to summarise(), head(), and tail() no longer eagerly evaluate: this means you need to call either compute() (to evaluate it and produce an Arrow Table) or collect() (to evaluate and pull the Table into an R data.frame) to see the results. Second, the order of rows in a dataset query is no longer determinisitic due to the way the parallelization of work happens in the C++ library. This means that you can’t assume that the results of a query will be in the same order as the rows of data in the files on disk. If you do need a stable sort order, call arrange() to specify ordering. While these changes are a break from past arrow behavior, they are consistent with many dbplyr backends and are needed to allow queries to scale beyond data-frame workflows that can fit into memory. Integration with DuckDB The Arrow engine is not the only new way to query Arrow Datasets in this release. If you have the duckdb package installed, you can hand off an Arrow Dataset or query object to DuckDB for further querying using the to_duckdb() function. This allows you to use duckdb’s dbplyr methods, as well as its SQL interface, to aggregate data. DuckDB supports filter pushdown, so you can take advantage of Arrow Datasets and Arrow-based optimizations even within a DuckDB SQL query with a where clause. Filtering and column projection specified before the to_duckdb() call in a pipeline is evaluated in Arrow; this can be helpful in some circumstances like complicated dbplyr pipelines. You can also hand off DuckDB data (or the result of a query) to arrow with the to_arrow() call. In the example below, we are looking at flights between NYC and Chicago, and want to avoid the worst-of-the-worst delays. To do this, we can use percent_rank(); however that requires a window function which isn’t yet available in Arrow, so let’s try sending the data to DuckDB to do that, then pull it back into Arrow: library(arrow, warn.conflicts = FALSE) library(dplyr, warn.conflicts = FALSE) flights_filtered &amp;lt;- arrow_table(nycflights13::flights) %&amp;gt;% select(carrier, origin, dest, arr_delay) %&amp;gt;% # arriving early doesn&apos;t matter, so call negative delays 0 mutate(arr_delay = pmax(arr_delay, 0)) %&amp;gt;% to_duckdb() %&amp;gt;% # for each carrier-origin-dest, take the worst 5% of delays group_by(carrier, origin, dest) %&amp;gt;% mutate(arr_delay_rank = percent_rank(arr_delay)) %&amp;gt;% filter(arr_delay_rank &amp;gt; 0.95) head(flights_filtered) #&amp;gt; # Source: lazy query [?? x 5] #&amp;gt; # Database: duckdb_connection #&amp;gt; # Groups: carrier, origin, dest #&amp;gt; carrier origin dest arr_delay arr_delay_rank #&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; #&amp;gt; 1 9E JFK RIC 119 0.952 #&amp;gt; 2 9E JFK RIC 125 0.956 #&amp;gt; 3 9E JFK RIC 137 0.960 #&amp;gt; 4 9E JFK RIC 137 0.960 #&amp;gt; 5 9E JFK RIC 158 0.968 #&amp;gt; 6 9E JFK RIC 163 0.972 Now we have all of the flights filtered to those that are the worst-of-the-worst, and stored as a dbplyr lazy tbl with our DuckDB connection. This is an example of using Arrow -&amp;gt; DuckDB. But we can do more: we can then bring that data back into Arrow just as easily. For the rest of our analysis, we pick up where we left off with the tbl referring to the DuckDB query: # pull data back into arrow to complete analysis flights_filtered %&amp;gt;% to_arrow() %&amp;gt;% # now summarise to get mean/min group_by(carrier, origin, dest) %&amp;gt;% summarise( arr_delay_mean = mean(arr_delay), arr_delay_min = min(arr_delay), num_flights = n() ) %&amp;gt;% filter(dest %in% c(&quot;ORD&quot;, &quot;MDW&quot;)) %&amp;gt;% arrange(desc(arr_delay_mean)) %&amp;gt;% collect() #&amp;gt; # A tibble: 10 × 6 #&amp;gt; # Groups: carrier, origin [10] #&amp;gt; carrier origin dest arr_delay_mean arr_delay_min num_flights #&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; #&amp;gt; 1 MQ EWR ORD 190. 103 113 #&amp;gt; 2 9E JFK ORD 185. 134 52 #&amp;gt; 3 UA LGA ORD 179. 101 157 #&amp;gt; 4 WN LGA MDW 178. 107 103 #&amp;gt; 5 AA JFK ORD 178. 133 19 #&amp;gt; 6 B6 JFK ORD 174. 129 46 #&amp;gt; 7 WN EWR MDW 167. 107 103 #&amp;gt; 8 UA EWR ORD 149. 87 189 #&amp;gt; 9 AA LGA ORD 135. 78 280 #&amp;gt; 10 EV EWR ORD 35 35 1 And just like that, we’ve passed data back and forth between Arrow and DuckDB without having to write a single file to disk! Expanded use of ALTREP We are continuing our use of R’s ALTREP where possible. In 5.0.0 there were a limited set of circumstances that took advantage of ALTREP, but in 6.0.0 we have expanded types to include strings, as well as vectors with NAs. library(microbenchmark) library(arrow) tbl &amp;lt;- arrow_table(data.frame( x = rnorm(10000000), y = sample(c(letters, NA), 10000000, replace = TRUE) )) with_altrep &amp;lt;- function(data){ options(arrow.use_altrep = TRUE) as.data.frame(data) } without_altrep &amp;lt;- function(data){ options(arrow.use_altrep = FALSE) as.data.frame(data) } microbenchmark( without_altrep(tbl), with_altrep(tbl) ) #&amp;gt; Unit: milliseconds #&amp;gt; expr min lq mean median uq max neval #&amp;gt; without_altrep(tbl) 191.0788 213.82235 249.65076 225.52120 244.26977 512.1652 100 #&amp;gt; with_altrep(tbl) 48.7152 50.97269 65.56832 52.93795 55.24505 338.4602 100 Airgapped installation on Linux With every release, we continue to improve the installation experience on Linux. Unlike macOS and Windows, CRAN does not host binary packages for Linux, and unless you’re using a service like RStudio Package Manger that hosts binaries, you have to build arrow from source. Because Arrow involves a large C++ project, this can be slow and sensitive to differences in build environments. To ensure a reliable installation experience, we work hard to test on a wide range of platforms and configurations and eagerly seek to simplify the process so that install.packages(&quot;arrow&quot;) just works and you don’t have to think about it. A big improvement in 6.0.0 is that arrow can now install in a fully offline mode. The R package now includes the C++ source, so it does not need to be downloaded at build time. This does not include optional dependencies like compression libraries, the AWS SDK for accessing data in S3, and more. For folks who need to install Arrow on an airgapped server with all of those features, we have included a helper function to download and assemble a “fat” pacakge that contains everything that would be downloaded lazily at build time. The function create_package_with_all_dependencies() can be run from a computer that does have access to the internet, and creates a fat-source package which can then be transferred and installed on a server without connectivity. This helper is also available on GitHub without installing the arrow package. For more installation see the docs. Another installation change is that we’ve changed the source build to fail cleanly if the C++ library is not found or cannot be built. Previously, if the C++ library failed to build, you would get a successful R package installation, but the package wouldn’t do anything useful, it would just tell you to reinstall. This was helpful back in the early days of the package when we weren’t confident it would build everywhere that CRAN checked, but we now have much more experience (and extensive testing). In recent months this failure mode caused more confusion than it was worth, and it led many people to think that after you install arrow, you always have to install_arrow() again. Thanks This is a significant milestone for Arrow, and the R package specifically, and there is much gratitude to go around. In the 6.0.0 release, there were 77 individuals who contributed to Arrow, many of whom did the heavy lifting in the C++ library to make the new dataset query features a reality. Specifically in the R package, we wanted to acknowledge Phillip Cloud, Dewey Dunnington, Dragoș Moldovan-Grünfeld, Matt Peterson, and Percy Camilo Triveño Aucahuasi for their their first contributions to the R package. And a special thanks goes to Karl Dunkle Werner for the hard work on the offline package build! We also want to thank you in advance for your help. For this release of the Arrow query engine, we’ve focused our effort on getting the core functionality implemented. (In fact, this first release is something of an R-exclusive: bindings for these features haven’t yet been added to pyarrow, the Python Arrow library!) By focusing on the essentials, it means that there are a number of performance optimizations we plan to do but didn’t have time for in this release–and there are surely more issues to improve that we don’t yet know. We are eager for your feedback: please let us know of any issues you encounter so that we can improve these for our next release.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arrow.apache.org/img/arrow.png" /><media:content medium="image" url="https://arrow.apache.org/img/arrow.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow 6.0.0 Release</title><link href="https://arrow.apache.org/blog/2021/11/04/6.0.0-release/" rel="alternate" type="text/html" title="Apache Arrow 6.0.0 Release" /><published>2021-11-04T02:00:00-04:00</published><updated>2021-11-04T02:00:00-04:00</updated><id>https://arrow.apache.org/blog/2021/11/04/6.0.0-release</id><content type="html" xml:base="https://arrow.apache.org/blog/2021/11/04/6.0.0-release/">&lt;!--

--&gt;

&lt;p&gt;The Apache Arrow team is pleased to announce the 6.0.0 release. This covers
over 3 months of development work and includes &lt;a href=&quot;https://issues.apache.org/jira/issues/?jql=project%20%3D%20ARROW%20AND%20status%20%3D%20Resolved%20AND%20fixVersion%20%3D%206.0.0&quot;&gt;&lt;strong&gt;572 resolved issues&lt;/strong&gt;&lt;/a&gt;
from &lt;a href=&quot;/release/6.0.0.html#contributors&quot;&gt;&lt;strong&gt;77 distinct contributors&lt;/strong&gt;&lt;/a&gt;. See the Install Page to learn how to
get the libraries for your platform.&lt;/p&gt;

&lt;p&gt;The release notes below are not exhaustive and only expose selected highlights
of the release. Many other bugfixes and improvements have been made: we refer
you to the &lt;a href=&quot;/release/6.0.0.html&quot;&gt;complete changelog&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;community&quot;&gt;Community&lt;/h2&gt;

&lt;p&gt;Since the 5.0.0 release, Nic Crane, QP Hou, Jiayu Liu, and Matt Topol have been invited to be committers, and Neville Dipale has joined the Project Management Committee (PMC). Thanks for your contributions and participation in the project!&lt;/p&gt;

&lt;h2 id=&quot;columnar-format-notes&quot;&gt;Columnar Format Notes&lt;/h2&gt;

&lt;p&gt;A new calendar interval type consisting of Month, Day and Nanoseconds has been added to the specification.  Reference implementations existing in Java, C++ and Python.&lt;/p&gt;

&lt;h2 id=&quot;arrow-flight-rpc-notes&quot;&gt;Arrow Flight RPC notes&lt;/h2&gt;

&lt;p&gt;GLib and Ruby have added bindings for Arrow Flight.&lt;/p&gt;

&lt;p&gt;While not part of the release, work is ongoing on Arrow Flight SQL, which defines a protocol for clients to communicate with SQL databases using Arrow Flight. For those interested in the project, please reach out on the &lt;a href=&quot;https://arrow.apache.org/community/&quot;&gt;mailing list&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;c-notes&quot;&gt;C++ notes&lt;/h2&gt;

&lt;p&gt;The month-day-nano interval type has been added (ARROW-13628).&lt;/p&gt;

&lt;p&gt;Various APIs, including extension types and scalars, are no longer experimental (ARROW-5244).&lt;/p&gt;

&lt;p&gt;Support for Visual Studio 2015 was dropped (ARROW-14070).&lt;/p&gt;

&lt;h3 id=&quot;compute-layer&quot;&gt;Compute Layer&lt;/h3&gt;

&lt;p&gt;A basic in-memory query engine has been implemented and is accessible from the R bindings. Operations including filter, project, sort, equality joins, and various aggregations are supported.&lt;/p&gt;

&lt;p&gt;The following compute functions have been added:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;aggregate functions: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;approximate_median&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;count_distinct&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;product&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;hash aggregate functions: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hash_all&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hash_any&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hash_approximate_median&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hash_count_distinct&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hash_distinct&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hash_max&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hash_mean&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hash_min&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hash_product&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hash_stdev&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hash_variance&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;scalar arithmetic functions: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;logb&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;round&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;round_to_multiple&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;scalar string functions: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ascii_capitalize&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ascii_swapcase&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ascii_title&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;utf8_capitalize&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;utf8_swapcase&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;utf8_title&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;scalar temporal functions: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;assume_timezone&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;day_time_interval_between&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;days_between&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hours_between&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;microseconds_between&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;milliseconds_between&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;minutes_between&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;month_day_nano_interval_between&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;month_interval_between&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nanoseconds_between&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quarters_between&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;seconds_between&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;strftime&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;us_week&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;week&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;weeks_between&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;years_between&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;other scalar functions: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;choose&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_element&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;vector functions: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;drop_null&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;select_k_unstable&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In general, type support has been improved for most of the compute functions, but work here is ongoing, particularly around decimal support.&lt;/p&gt;

&lt;p&gt;Crashes have been fixed in particular cases for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;take&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filter&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;unique&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;value_counts&lt;/code&gt; (ARROW-13474, ARROW-13509, ARROW-14129).&lt;/p&gt;

&lt;p&gt;Hash aggregations (i.e. group by) supports scalar and array values (ARROW-13737, ARROW-14027).&lt;/p&gt;

&lt;p&gt;Temporal functions are now timezone-aware (e.g. when extracting the hour of a timestamp) (ARROW-12980).&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;count&lt;/code&gt; can optionally count all values, not just null or non-null values (ARROW-13574).&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fill_null&lt;/code&gt; has been replaced by the more general &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;coalesce&lt;/code&gt; (ARROW-7179).&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;is_null&lt;/code&gt; can optionally consider NaN as null (ARROW-12959).&lt;/p&gt;

&lt;p&gt;Sorting has been optimized (ARROW-10898, ARROW-14165). Also, null values can now be sorted at either the beginning or the end (ARROW-12063).&lt;/p&gt;

&lt;h3 id=&quot;csv&quot;&gt;CSV&lt;/h3&gt;

&lt;p&gt;The CSV reader can read time32 and time64 types, and will infer time32 values for columns in the format “hh:mm” and “hh:mm:ss” (ARROW-11243).&lt;/p&gt;

&lt;p&gt;The decimal point can be customized when reading (ARROW-13421).&lt;/p&gt;

&lt;p&gt;The streaming reader will not unintentionally infer null-typed columns when using the various skip options (ARROW-13441).&lt;/p&gt;

&lt;p&gt;If a row has an incorrect number of columns, now the row can be skipped instead of raising an error (ARROW-12673).&lt;/p&gt;

&lt;p&gt;The option &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quoted_strings_can_be_null&lt;/code&gt; applies to all column types now, not just strings (ARROW-13580). When quoting is disabled entirely, the reader now takes advantage of this to improve performance (ARROW-14150).&lt;/p&gt;

&lt;p&gt;A CSVWriter object is now exposed, allowing for incremental writing (ARROW-11828). Dates can now be written (ARROW-12540).&lt;/p&gt;

&lt;h3 id=&quot;dataset-layer&quot;&gt;Dataset Layer&lt;/h3&gt;

&lt;p&gt;The dataset writer was refactored, and now supports more options, including a limit on the number of files open at once, compatibility with the async scanner, a limit on the number of rows written per file, and control over what to do when files already exist in the target directory (ARROW-13650). Additionally, the query engine can feed into the dataset writer as a sink (ARROW-13542).&lt;/p&gt;

&lt;p&gt;The asynchronous scanner now properly respects backpressure (ARROW-13611, ARROW-14192), as does the writer (ARROW-14191).&lt;/p&gt;

&lt;p&gt;ORC datasets are supported (ARROW-13572) with support for column projection pushdown (ARROW-13797).&lt;/p&gt;

&lt;p&gt;The Parquet/IPC format readers now respect the batch_size scanner option (ARROW-14024). Also, the Parquet reader now properly implements readahead for better performance (ARROW-14026).&lt;/p&gt;

&lt;h3 id=&quot;io-and-filesystem-layer&quot;&gt;IO and Filesystem Layer&lt;/h3&gt;

&lt;p&gt;The retry strategy of S3FileSystem can be customized (ARROW-13508). When writing to an existing bucket as a user with limited permissions, Arrow will no longer emit a spurious “Access Denied” error (ARROW-13685).&lt;/p&gt;

&lt;p&gt;On MacOS with NFS mounts, a “[errno 25] Inappropriate ioctl for device” error was fixed (ARROW-13983).&lt;/p&gt;

&lt;p&gt;The basics of a Google Cloud Storage filesystem have been added; work is in progress for full support (ARROW-8147, ARROW-14222, ARROW-14223, ARROW-14232, ARROW-14236, ARROW-14345, ARROW-14157).&lt;/p&gt;

&lt;h3 id=&quot;json&quot;&gt;JSON&lt;/h3&gt;

&lt;p&gt;A crash was fixed when duplicate keys were present (ARROW-14109).&lt;/p&gt;

&lt;h3 id=&quot;parquet&quot;&gt;Parquet&lt;/h3&gt;

&lt;p&gt;Written min/max and null_count statistics for dictionary types were corrected (ARROW-11634, ARROW-12513).
null_count statistics for columns that contain repeated data where corrected.&lt;/p&gt;

&lt;p&gt;file_offset for row groups was not being populated according to the specification, this issue has been corrected.&lt;/p&gt;

&lt;p&gt;Column selection now works for repeated columns and structs of more then one level.&lt;/p&gt;

&lt;p&gt;An error with large files when built with Thrift 0.14 was fixed (ARROW-13655).&lt;/p&gt;

&lt;p&gt;The ParquetVersion enum was updated with more values to support finer-grained Parquet format version selection (ARROW-13794).&lt;/p&gt;

&lt;p&gt;Writer performance was improved by avoiding repeated dynamic casts (ARROW-13965).&lt;/p&gt;

&lt;h2 id=&quot;c-notes-1&quot;&gt;C# notes&lt;/h2&gt;

&lt;p&gt;This release includes improved support for dictionary arrays, as well as integration testing with the other Arrow implementations for the primitive and decimal types&lt;/p&gt;

&lt;h2 id=&quot;go-notes&quot;&gt;Go notes&lt;/h2&gt;

&lt;h3 id=&quot;bug-fixes&quot;&gt;Bug Fixes&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Fixed handling of the zero value for Decimal128 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FromBigInt&lt;/code&gt; &lt;a href=&quot;https://github.com/apache/arrow/pull/10796&quot;&gt;#10796&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Fixed various “too many releases” errors in the tests allowing all tests to be run using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;assert&lt;/code&gt; build tag in CI from now on, including a bug when writing slices of String, Binary or FixedWidthType arrays via ipc.Writer &lt;a href=&quot;https://github.com/apache/arrow/pull/11270&quot;&gt;#11270&lt;/a&gt;, &lt;a href=&quot;https://github.com/apache/arrow/pull/11276&quot;&gt;#11276&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Fixed builds on ARM and s390x architectures &lt;a href=&quot;https://github.com/apache/arrow/pull/11299&quot;&gt;#11299&lt;/a&gt;, [#11305]((https://github.com/apache/arrow/pull/11305)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;enhancements&quot;&gt;Enhancements&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Added &lt;a href=&quot;https://github.com/apache/arrow/pull/11128&quot;&gt;Concatenate&lt;/a&gt; function for concatenating arrays&lt;/li&gt;
  &lt;li&gt;Implemented &lt;a href=&quot;https://github.com/apache/arrow/pull/11024&quot;&gt;Scalar&lt;/a&gt; values and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MakeArrayFromScalar&lt;/code&gt; function [#11252]((https://github.com/apache/arrow/pull/11252)&lt;/li&gt;
  &lt;li&gt;Added cgo &lt;a href=&quot;https://github.com/apache/arrow/pull/11206&quot;&gt;optional allocator&lt;/a&gt; for allocating memory using the C++ memory pool for use with the C Data &lt;a href=&quot;https://github.com/apache/arrow/pull/11037&quot;&gt;import&lt;/a&gt; and &lt;a href=&quot;https://github.com/apache/arrow/pull/11220&quot;&gt;export&lt;/a&gt; APIs&lt;/li&gt;
  &lt;li&gt;Added support for Month, Day, Nano interval type &lt;a href=&quot;https://github.com/apache/arrow/pull/11310&quot;&gt;#11310&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Completed &lt;a href=&quot;https://github.com/apache/arrow/pull/10716&quot;&gt;Encoding&lt;/a&gt; package for Parquet, added &lt;a href=&quot;https://github.com/apache/arrow/pull/10951&quot;&gt;Metadata&lt;/a&gt; package.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;version-compatibility-update&quot;&gt;Version Compatibility Update&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Release process updated to add proper git tags for Go release for Module aware version tracking (&lt;a href=&quot;https://github.com/apache/arrow/pull/11312&quot;&gt;#11312&lt;/a&gt;) meaning that this release will be correctly tagged as v6.0.0 in go.mod and pkg.go.dev and future releases will be correctly versioned with the Go module system.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;java-notes&quot;&gt;Java notes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Some dependent libraries were upgraded. In particular, grpc upgraded to 1.41.0, netty upgraded to 2.0.43, and orc upgraded to 1.7.0. (ARROW-14198) (ARROW-14049)&lt;/li&gt;
  &lt;li&gt;Fixed the problem of appending BitVectors in batch (ARROW-13981)&lt;/li&gt;
  &lt;li&gt;Code coverage support enabled for Java (ARROW-13859)&lt;/li&gt;
  &lt;li&gt;Fixed the incorrect string representations for unsigned integer vectors (ARROW-13792)&lt;/li&gt;
  &lt;li&gt;Reduced the memory consumption of JDBC adapters by reusing record batches (ARROW-13733)&lt;/li&gt;
  &lt;li&gt;Allowed NullVectors to have distinct field names (ARROW-13645)&lt;/li&gt;
  &lt;li&gt;Some APIs that have been deprecated for long have been removed (ARROW-13544)&lt;/li&gt;
  &lt;li&gt;Allowed passing empty columns for projection in Dataset (ARROW-13257)&lt;/li&gt;
  &lt;li&gt;A Java implementation of Arrow C data interface was provided (ARROW-12965)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;javascript-notes&quot;&gt;JavaScript notes&lt;/h2&gt;

&lt;p&gt;This release fixes builds with the latest TypeScript versions and ESM tree shaking.&lt;/p&gt;

&lt;p&gt;Deprecation notice: in Arrow 7, we will remove the compute code from Arrow JS.&lt;/p&gt;

&lt;h2 id=&quot;python-notes&quot;&gt;Python notes&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Many new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pyarrow.compute&lt;/code&gt; functions are available (see the C++ notes above for more details), and introspection of the functions was improved so that they look more like standard Python functions.&lt;/li&gt;
  &lt;li&gt;All Python functions and classes should now have documented parameters in the API reference.&lt;/li&gt;
  &lt;li&gt;SIMD optimization is now enabled in M1 wheels&lt;/li&gt;
  &lt;li&gt;Wheels are now built for more Python versions on M1 systems.&lt;/li&gt;
  &lt;li&gt;PyArrow is now compatible with Python 3.10&lt;/li&gt;
  &lt;li&gt;Creating Arrow arrays now supports more than just numpy arrays as masks&lt;/li&gt;
  &lt;li&gt;Printing Tables now previews the values in the columns&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;copy_files&lt;/code&gt; is now available in Python&lt;/li&gt;
  &lt;li&gt;Datasets now support ORC files&lt;/li&gt;
  &lt;li&gt;Sets are now supported when building arrays or converting from pandas.&lt;/li&gt;
  &lt;li&gt;39 bugs have been fixed.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;r-notes&quot;&gt;R notes&lt;/h2&gt;

&lt;p&gt;This release adds grouped aggregation and joins in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dplyr&lt;/code&gt; interface, on top of the new Arrow C++ query engine. There is also support for using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duckdb&lt;/code&gt; to query Arrow datasets. For more details, see the &lt;a href=&quot;/docs/r/news/&quot;&gt;complete R changelog&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;ruby-and-c-glib-notes&quot;&gt;Ruby and C GLib notes&lt;/h2&gt;

&lt;h3 id=&quot;ruby&quot;&gt;Ruby&lt;/h3&gt;

&lt;p&gt;The updates of Red Arrow etc. consists of the following improvements:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Red Arrow
    &lt;ul&gt;
      &lt;li&gt;Added &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Arrow::RecordBatchReader&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Support to convert an array of symbols to a dictionary array&lt;/li&gt;
      &lt;li&gt;Add support for building and converting map&lt;/li&gt;
      &lt;li&gt;Add support for group aggregation&lt;/li&gt;
      &lt;li&gt;Use compute kernels for the implementation of slicers&lt;/li&gt;
      &lt;li&gt;Support a Range and an Array of selectors in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Arrow::Table#[]&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Arrow::RecordBatch#[]&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Separate min and max aggregators&lt;/li&gt;
      &lt;li&gt;Support a hash slicer; a scalar value is for equality matching, and a range is for between matching&lt;/li&gt;
      &lt;li&gt;Add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Arrow::TableConcatenateOptions&lt;/code&gt; and conversion from a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Hash&lt;/code&gt; for convenience&lt;/li&gt;
      &lt;li&gt;Add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Arrow::Expression&lt;/code&gt; and conversion from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Array&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Hash&lt;/code&gt; for convenience&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Red Arrow Dataset
    &lt;ul&gt;
      &lt;li&gt;Add support for loading from directories&lt;/li&gt;
      &lt;li&gt;Add support for writing&lt;/li&gt;
      &lt;li&gt;Add filter expression support in a loader&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Red Arrow Flight
    &lt;ul&gt;
      &lt;li&gt;Add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ArrowFlight::Client#do_get&lt;/code&gt; support&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;c-glib&quot;&gt;C GLib&lt;/h3&gt;

&lt;p&gt;The updates of Arrow GLib etc. consists of the following improvements:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Arrow GLib
    &lt;ul&gt;
      &lt;li&gt;Add the following new functions:
        &lt;ul&gt;
          &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;garrow_record_batch_reader_new&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;garrow_record_batch_reader_read_all&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;garrow_union_scalar_get_type_code&lt;/code&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;type_code&lt;/code&gt; supports in union scalar types&lt;/li&gt;
      &lt;li&gt;Add C ABI support&lt;/li&gt;
      &lt;li&gt;Add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GArrowCountOptions&lt;/code&gt; and let count functions support it&lt;/li&gt;
      &lt;li&gt;Add support for group aggregation&lt;/li&gt;
      &lt;li&gt;Add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GArrowSetLookupOptions&lt;/code&gt; for options of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;is_in&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;index_in&lt;/code&gt; kernels&lt;/li&gt;
      &lt;li&gt;Add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GArrowVarianceOptions&lt;/code&gt; to specify the calculation options for variance and standard deviation kernels&lt;/li&gt;
      &lt;li&gt;Add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GArrowFunctionDoc&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GArrowTableConcatenateOptions&lt;/code&gt; and let &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;garrow_table_concatenate&lt;/code&gt; support it&lt;/li&gt;
      &lt;li&gt;Add expressions support&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Arrow Dataset GLib
    &lt;ul&gt;
      &lt;li&gt;Add support for writing data&lt;/li&gt;
      &lt;li&gt;Support recursive scanning in a directory&lt;/li&gt;
      &lt;li&gt;Add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gadataset_scanner_builder_set_filter&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Make &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;use_async&lt;/code&gt; of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GADatasetScannerBuilder&lt;/code&gt; a property, and remove &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gadataset_scanner_builder_use_async&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Arrow Flight GLib
    &lt;ul&gt;
      &lt;li&gt;Add DoGet support:
        &lt;ul&gt;
          &lt;li&gt;New functions: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gaflight_client_do_get&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gaflight_server_do_get&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;New classes: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GAFlightStreamReader&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GAFlightStreamChunk&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GAFlightRecordBatchReader&lt;/code&gt;,  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GAFlightDataStream&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GAFlightRecordBatchStream&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GAFlightServerCallContext&lt;/code&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Change the argument order of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gaflight_client_list_flights&lt;/code&gt; function&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Parquet GLib
    &lt;ul&gt;
      &lt;li&gt;Add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gparquet_arrow_file_reader_get_n_rows&lt;/code&gt; function&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;rust-notes&quot;&gt;Rust notes&lt;/h2&gt;

&lt;p&gt;Rust continues to release minor versions every 2 weeks in addition to
a major version with the rest of the Arrow language
implementations. Thus most enhancements have been incrementally
released over the last 3 months as part of the 5.x.&lt;/p&gt;

&lt;p&gt;The DataFusion and Ballista sub projects have begun releasing at their
own cadence which is expected to continue in the next few weeks.&lt;/p&gt;

&lt;p&gt;Major changes in the 6.0.0 release include support for the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MapArray&lt;/code&gt;
array type, improved lower level &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ArrayData&lt;/code&gt; APIs to better
communicate safety, and a faster (but unstable) sorting kernel.&lt;/p&gt;

&lt;p&gt;For additional details on the 6.0.0
Rust implementation, please see the &lt;a href=&quot;https://github.com/apache/arrow-rs/blob/6.0.0/CHANGELOG.md&quot;&gt;Arrow Rust
CHANGELOG&lt;/a&gt;&lt;/p&gt;</content><author><name>pmc</name></author><category term="release" /><summary type="html">The Apache Arrow team is pleased to announce the 6.0.0 release. This covers over 3 months of development work and includes 572 resolved issues from 77 distinct contributors. See the Install Page to learn how to get the libraries for your platform. The release notes below are not exhaustive and only expose selected highlights of the release. Many other bugfixes and improvements have been made: we refer you to the complete changelog. Community Since the 5.0.0 release, Nic Crane, QP Hou, Jiayu Liu, and Matt Topol have been invited to be committers, and Neville Dipale has joined the Project Management Committee (PMC). Thanks for your contributions and participation in the project! Columnar Format Notes A new calendar interval type consisting of Month, Day and Nanoseconds has been added to the specification. Reference implementations existing in Java, C++ and Python. Arrow Flight RPC notes GLib and Ruby have added bindings for Arrow Flight. While not part of the release, work is ongoing on Arrow Flight SQL, which defines a protocol for clients to communicate with SQL databases using Arrow Flight. For those interested in the project, please reach out on the mailing list. C++ notes The month-day-nano interval type has been added (ARROW-13628). Various APIs, including extension types and scalars, are no longer experimental (ARROW-5244). Support for Visual Studio 2015 was dropped (ARROW-14070). Compute Layer A basic in-memory query engine has been implemented and is accessible from the R bindings. Operations including filter, project, sort, equality joins, and various aggregations are supported. The following compute functions have been added: aggregate functions: approximate_median, count_distinct, max, min, product hash aggregate functions: hash_all, hash_any, hash_approximate_median, hash_count_distinct, hash_distinct, hash_max, hash_mean, hash_min, hash_product, hash_stdev, hash_variance scalar arithmetic functions: logb, round, round_to_multiple scalar string functions: ascii_capitalize, ascii_swapcase, ascii_title, utf8_capitalize, utf8_swapcase, utf8_title scalar temporal functions: assume_timezone, day_time_interval_between, days_between, hours_between, microseconds_between, milliseconds_between, minutes_between, month_day_nano_interval_between, month_interval_between, nanoseconds_between, quarters_between, seconds_between, strftime, us_week, week, weeks_between, years_between other scalar functions: choose, list_element vector functions: drop_null, select_k_unstable In general, type support has been improved for most of the compute functions, but work here is ongoing, particularly around decimal support. Crashes have been fixed in particular cases for take, filter, unique, and value_counts (ARROW-13474, ARROW-13509, ARROW-14129). Hash aggregations (i.e. group by) supports scalar and array values (ARROW-13737, ARROW-14027). Temporal functions are now timezone-aware (e.g. when extracting the hour of a timestamp) (ARROW-12980). count can optionally count all values, not just null or non-null values (ARROW-13574). fill_null has been replaced by the more general coalesce (ARROW-7179). is_null can optionally consider NaN as null (ARROW-12959). Sorting has been optimized (ARROW-10898, ARROW-14165). Also, null values can now be sorted at either the beginning or the end (ARROW-12063). CSV The CSV reader can read time32 and time64 types, and will infer time32 values for columns in the format “hh:mm” and “hh:mm:ss” (ARROW-11243). The decimal point can be customized when reading (ARROW-13421). The streaming reader will not unintentionally infer null-typed columns when using the various skip options (ARROW-13441). If a row has an incorrect number of columns, now the row can be skipped instead of raising an error (ARROW-12673). The option quoted_strings_can_be_null applies to all column types now, not just strings (ARROW-13580). When quoting is disabled entirely, the reader now takes advantage of this to improve performance (ARROW-14150). A CSVWriter object is now exposed, allowing for incremental writing (ARROW-11828). Dates can now be written (ARROW-12540). Dataset Layer The dataset writer was refactored, and now supports more options, including a limit on the number of files open at once, compatibility with the async scanner, a limit on the number of rows written per file, and control over what to do when files already exist in the target directory (ARROW-13650). Additionally, the query engine can feed into the dataset writer as a sink (ARROW-13542). The asynchronous scanner now properly respects backpressure (ARROW-13611, ARROW-14192), as does the writer (ARROW-14191). ORC datasets are supported (ARROW-13572) with support for column projection pushdown (ARROW-13797). The Parquet/IPC format readers now respect the batch_size scanner option (ARROW-14024). Also, the Parquet reader now properly implements readahead for better performance (ARROW-14026). IO and Filesystem Layer The retry strategy of S3FileSystem can be customized (ARROW-13508). When writing to an existing bucket as a user with limited permissions, Arrow will no longer emit a spurious “Access Denied” error (ARROW-13685). On MacOS with NFS mounts, a “[errno 25] Inappropriate ioctl for device” error was fixed (ARROW-13983). The basics of a Google Cloud Storage filesystem have been added; work is in progress for full support (ARROW-8147, ARROW-14222, ARROW-14223, ARROW-14232, ARROW-14236, ARROW-14345, ARROW-14157). JSON A crash was fixed when duplicate keys were present (ARROW-14109). Parquet Written min/max and null_count statistics for dictionary types were corrected (ARROW-11634, ARROW-12513). null_count statistics for columns that contain repeated data where corrected. file_offset for row groups was not being populated according to the specification, this issue has been corrected. Column selection now works for repeated columns and structs of more then one level. An error with large files when built with Thrift 0.14 was fixed (ARROW-13655). The ParquetVersion enum was updated with more values to support finer-grained Parquet format version selection (ARROW-13794). Writer performance was improved by avoiding repeated dynamic casts (ARROW-13965). C# notes This release includes improved support for dictionary arrays, as well as integration testing with the other Arrow implementations for the primitive and decimal types Go notes Bug Fixes Fixed handling of the zero value for Decimal128 FromBigInt #10796 Fixed various “too many releases” errors in the tests allowing all tests to be run using the assert build tag in CI from now on, including a bug when writing slices of String, Binary or FixedWidthType arrays via ipc.Writer #11270, #11276 Fixed builds on ARM and s390x architectures #11299, [#11305]((https://github.com/apache/arrow/pull/11305) Enhancements Added Concatenate function for concatenating arrays Implemented Scalar values and MakeArrayFromScalar function [#11252]((https://github.com/apache/arrow/pull/11252) Added cgo optional allocator for allocating memory using the C++ memory pool for use with the C Data import and export APIs Added support for Month, Day, Nano interval type #11310 Completed Encoding package for Parquet, added Metadata package. Version Compatibility Update Release process updated to add proper git tags for Go release for Module aware version tracking (#11312) meaning that this release will be correctly tagged as v6.0.0 in go.mod and pkg.go.dev and future releases will be correctly versioned with the Go module system. Java notes Some dependent libraries were upgraded. In particular, grpc upgraded to 1.41.0, netty upgraded to 2.0.43, and orc upgraded to 1.7.0. (ARROW-14198) (ARROW-14049) Fixed the problem of appending BitVectors in batch (ARROW-13981) Code coverage support enabled for Java (ARROW-13859) Fixed the incorrect string representations for unsigned integer vectors (ARROW-13792) Reduced the memory consumption of JDBC adapters by reusing record batches (ARROW-13733) Allowed NullVectors to have distinct field names (ARROW-13645) Some APIs that have been deprecated for long have been removed (ARROW-13544) Allowed passing empty columns for projection in Dataset (ARROW-13257) A Java implementation of Arrow C data interface was provided (ARROW-12965) JavaScript notes This release fixes builds with the latest TypeScript versions and ESM tree shaking. Deprecation notice: in Arrow 7, we will remove the compute code from Arrow JS. Python notes Many new pyarrow.compute functions are available (see the C++ notes above for more details), and introspection of the functions was improved so that they look more like standard Python functions. All Python functions and classes should now have documented parameters in the API reference. SIMD optimization is now enabled in M1 wheels Wheels are now built for more Python versions on M1 systems. PyArrow is now compatible with Python 3.10 Creating Arrow arrays now supports more than just numpy arrays as masks Printing Tables now previews the values in the columns copy_files is now available in Python Datasets now support ORC files Sets are now supported when building arrays or converting from pandas. 39 bugs have been fixed. R notes This release adds grouped aggregation and joins in the dplyr interface, on top of the new Arrow C++ query engine. There is also support for using duckdb to query Arrow datasets. For more details, see the complete R changelog. Ruby and C GLib notes Ruby The updates of Red Arrow etc. consists of the following improvements: Red Arrow Added Arrow::RecordBatchReader Support to convert an array of symbols to a dictionary array Add support for building and converting map Add support for group aggregation Use compute kernels for the implementation of slicers Support a Range and an Array of selectors in Arrow::Table#[] and Arrow::RecordBatch#[] Separate min and max aggregators Support a hash slicer; a scalar value is for equality matching, and a range is for between matching Add Arrow::TableConcatenateOptions and conversion from a Hash for convenience Add Arrow::Expression and conversion from Array and Hash for convenience Red Arrow Dataset Add support for loading from directories Add support for writing Add filter expression support in a loader Red Arrow Flight Add ArrowFlight::Client#do_get support C GLib The updates of Arrow GLib etc. consists of the following improvements: Arrow GLib Add the following new functions: garrow_record_batch_reader_new garrow_record_batch_reader_read_all garrow_union_scalar_get_type_code Add type_code supports in union scalar types Add C ABI support Add GArrowCountOptions and let count functions support it Add support for group aggregation Add GArrowSetLookupOptions for options of is_in and index_in kernels Add GArrowVarianceOptions to specify the calculation options for variance and standard deviation kernels Add GArrowFunctionDoc Add GArrowTableConcatenateOptions and let garrow_table_concatenate support it Add expressions support Arrow Dataset GLib Add support for writing data Support recursive scanning in a directory Add gadataset_scanner_builder_set_filter Make use_async of GADatasetScannerBuilder a property, and remove gadataset_scanner_builder_use_async Arrow Flight GLib Add DoGet support: New functions: gaflight_client_do_get and gaflight_server_do_get New classes: GAFlightStreamReader, GAFlightStreamChunk, GAFlightRecordBatchReader, GAFlightDataStream, GAFlightRecordBatchStream, and GAFlightServerCallContext Change the argument order of gaflight_client_list_flights function Parquet GLib Add gparquet_arrow_file_reader_get_n_rows function Rust notes Rust continues to release minor versions every 2 weeks in addition to a major version with the rest of the Arrow language implementations. Thus most enhancements have been incrementally released over the last 3 months as part of the 5.x. The DataFusion and Ballista sub projects have begun releasing at their own cadence which is expected to continue in the next few weeks. Major changes in the 6.0.0 release include support for the MapArray array type, improved lower level ArrayData APIs to better communicate safety, and a faster (but unstable) sorting kernel. For additional details on the 6.0.0 Rust implementation, please see the Arrow Rust CHANGELOG</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arrow.apache.org/img/arrow.png" /><media:content medium="image" url="https://arrow.apache.org/img/arrow.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow Ballista 0.5.0 Release</title><link href="https://arrow.apache.org/blog/2021/08/18/ballista-0.5.0/" rel="alternate" type="text/html" title="Apache Arrow Ballista 0.5.0 Release" /><published>2021-08-18T00:00:00-04:00</published><updated>2021-08-18T00:00:00-04:00</updated><id>https://arrow.apache.org/blog/2021/08/18/ballista-0.5.0</id><content type="html" xml:base="https://arrow.apache.org/blog/2021/08/18/ballista-0.5.0/">&lt;!--

--&gt;

&lt;p&gt;Ballista extends DataFusion to provide support for distributed queries. This is the first release of Ballista since 
the project was &lt;a href=&quot;https://arrow.apache.org/blog/2021/04/12/ballista-donation/&quot;&gt;donated&lt;/a&gt; to the Apache Arrow project 
and includes 80 commits from 11 contributors.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git shortlog -sn 4.0.0..5.0.0 ballista/rust/client ballista/rust/core ballista/rust/executor ballista/rust/scheduler
  27  Andy Grove
  15  Jiayu Liu
  12  Andrew Lamb
   8  Ximo Guanter
   6  Daniël Heres
   5  QP Hou
   2  Jorge Leitao
   1  Javier Goday
   1  K.I. (Dennis) Jung
   1  Mike Seddon
   1  sathis
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!--
$ git log --pretty=oneline 4.0.0..5.0.0 ballista/rust/client ballista/rust/core ballista/rust/executor ballista/rust/scheduler ballista-examples/ | wc -l
80
--&gt;

&lt;p&gt;The release notes below are not exhaustive and only expose selected highlights of the release. Many other bug fixes 
and improvements have been made: we refer you to the &lt;a href=&quot;https://github.com/apache/arrow-datafusion/blob/5.0.0/ballista/CHANGELOG.md&quot;&gt;complete changelog&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;performance-and-scalability&quot;&gt;Performance and Scalability&lt;/h1&gt;

&lt;p&gt;Ballista is now capable of running complex SQL queries at scale and supports scalable distributed joins. We have been 
benchmarking using individual queries from the TPC-H benchmark at scale factors up to 1000 (1 TB). When running against 
CSV files, performance is generally very close to DataFusion, and significantly faster in some cases due to the fact 
that the scheduler limits the number of concurrent tasks that run at any given time. Performance against large Parquet 
datasets is currently non ideal due to some issues (&lt;a href=&quot;https://github.com/apache/arrow-datafusion/issues/867&quot;&gt;#867&lt;/a&gt;, 
&lt;a href=&quot;https://github.com/apache/arrow-datafusion/issues/868&quot;&gt;#868&lt;/a&gt;) that we hope to resolve for the next release.&lt;/p&gt;

&lt;h1 id=&quot;new-features&quot;&gt;New Features&lt;/h1&gt;

&lt;p&gt;The main new features in this release are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ballista queries can now be executed by calling DataFrame.collect()&lt;/li&gt;
  &lt;li&gt;The shuffle mechanism has been re-implemented&lt;/li&gt;
  &lt;li&gt;Distributed hash-partitioned joins are now supported&lt;/li&gt;
  &lt;li&gt;Keda autoscaling is supported&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To get started with Ballista, refer to the &lt;a href=&quot;https://docs.rs/ballista/0.5.0/ballista/&quot;&gt;crate documentation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now that the basic functionality is in place, the focus for the next release will be to improve the performance and
scalability as well as improving the documentation.&lt;/p&gt;

&lt;h1 id=&quot;how-to-get-involved&quot;&gt;How to Get Involved&lt;/h1&gt;

&lt;p&gt;If you are interested in contributing to Ballista, we would love to have you! You
can help by trying out Ballista on some of your own data and projects and filing bug reports and helping to
improve the documentation, or contribute to the documentation, tests or code. A list of open issues suitable for
beginners is &lt;a href=&quot;https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22&quot;&gt;here&lt;/a&gt;
and the full list is &lt;a href=&quot;https://github.com/apache/arrow-datafusion/issues&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</content><author><name>pmc</name></author><category term="release" /><summary type="html">Ballista extends DataFusion to provide support for distributed queries. This is the first release of Ballista since the project was donated to the Apache Arrow project and includes 80 commits from 11 contributors. git shortlog -sn 4.0.0..5.0.0 ballista/rust/client ballista/rust/core ballista/rust/executor ballista/rust/scheduler 27 Andy Grove 15 Jiayu Liu 12 Andrew Lamb 8 Ximo Guanter 6 Daniël Heres 5 QP Hou 2 Jorge Leitao 1 Javier Goday 1 K.I. (Dennis) Jung 1 Mike Seddon 1 sathis The release notes below are not exhaustive and only expose selected highlights of the release. Many other bug fixes and improvements have been made: we refer you to the complete changelog. Performance and Scalability Ballista is now capable of running complex SQL queries at scale and supports scalable distributed joins. We have been benchmarking using individual queries from the TPC-H benchmark at scale factors up to 1000 (1 TB). When running against CSV files, performance is generally very close to DataFusion, and significantly faster in some cases due to the fact that the scheduler limits the number of concurrent tasks that run at any given time. Performance against large Parquet datasets is currently non ideal due to some issues (#867, #868) that we hope to resolve for the next release. New Features The main new features in this release are: Ballista queries can now be executed by calling DataFrame.collect() The shuffle mechanism has been re-implemented Distributed hash-partitioned joins are now supported Keda autoscaling is supported To get started with Ballista, refer to the crate documentation. Now that the basic functionality is in place, the focus for the next release will be to improve the performance and scalability as well as improving the documentation. How to Get Involved If you are interested in contributing to Ballista, we would love to have you! You can help by trying out Ballista on some of your own data and projects and filing bug reports and helping to improve the documentation, or contribute to the documentation, tests or code. A list of open issues suitable for beginners is here and the full list is here.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arrow.apache.org/img/arrow.png" /><media:content medium="image" url="https://arrow.apache.org/img/arrow.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow DataFusion 5.0.0 Release</title><link href="https://arrow.apache.org/blog/2021/08/18/datafusion-5.0.0/" rel="alternate" type="text/html" title="Apache Arrow DataFusion 5.0.0 Release" /><published>2021-08-18T00:00:00-04:00</published><updated>2021-08-18T00:00:00-04:00</updated><id>https://arrow.apache.org/blog/2021/08/18/datafusion-5.0.0</id><content type="html" xml:base="https://arrow.apache.org/blog/2021/08/18/datafusion-5.0.0/">&lt;!--

--&gt;

&lt;p&gt;The Apache Arrow team is pleased to announce the DataFusion 5.0.0 release. This covers 4 months of development work 
and includes 211 commits from the following 31 distinct contributors.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ git shortlog -sn 4.0.0..5.0.0 datafusion datafusion-cli datafusion-examples
    61  Jiayu Liu
    47  Andrew Lamb
    27  Daniël Heres
    13  QP Hou
    13  Andy Grove
     4  Javier Goday
     4  sathis
     3  Ruan Pearce-Authers
     3  Raphael Taylor-Davies
     3  Jorge Leitao
     3  Cui Wenzheng
     3  Mike Seddon
     3  Edd Robinson
     2  思维
     2  Liang-Chi Hsieh
     2  Michael Lu
     2  Parth Sarthy
     2  Patrick More
     2  Rich
     1  Charlie Evans
     1  Gang Liao
     1  Agata Naomichi
     1  Ritchie Vink
     1  Evan Chan
     1  Ruihang Xia
     1  Todd Treece
     1  Yichen Wang
     1  baishen
     1  Nga Tran
     1  rdettai
     1  Marco Neumann
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!--
$ git log --pretty=oneline 4.0.0..5.0.0 datafusion datafusion-cli datafusion-examples | wc -l
     211
--&gt;

&lt;p&gt;The release notes below are not exhaustive and only expose selected highlights of the release. Many other bug fixes 
and improvements have been made: we refer you to the complete 
&lt;a href=&quot;https://github.com/apache/arrow-datafusion/blob/5.0.0/datafusion/CHANGELOG.md&quot;&gt;changelog&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;performance&quot;&gt;Performance&lt;/h1&gt;

&lt;p&gt;There have been numerous performance improvements in this release. The following chart shows the relative 
performance of individual TPC-H queries compared to the previous release.&lt;/p&gt;

&lt;p&gt;&lt;i&gt;TPC-H @ scale factor 100, in parquet format. Concurrency 24.&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2021-08-18-datafusion500perf.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We also extended support for more TPC-H queries: q7, q8, q9 and q13 are running successfully in DataFusion 5.0.&lt;/p&gt;

&lt;h1 id=&quot;new-features&quot;&gt;New Features&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Initial support for SQL-99 Analytics (WINDOW functions)&lt;/li&gt;
  &lt;li&gt;Improved JOIN support: cross join, semi-join, anti join, and fixes to null handling&lt;/li&gt;
  &lt;li&gt;Improved EXPLAIN support&lt;/li&gt;
  &lt;li&gt;Initial implementation of metrics in the physical plan&lt;/li&gt;
  &lt;li&gt;Support for SELECT DISTINCT&lt;/li&gt;
  &lt;li&gt;Support for Json and NDJson formatted inputs&lt;/li&gt;
  &lt;li&gt;Query column with relations&lt;/li&gt;
  &lt;li&gt;Added more datetime related functions: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;now&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;date_trunc&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;to_timestamp_millis&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;to_timestamp_micros&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;to_timestamp_seconds&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Streaming Dataframe.collect&lt;/li&gt;
  &lt;li&gt;Support table column aliases&lt;/li&gt;
  &lt;li&gt;Answer count(*), min() and max() queries using only statistics&lt;/li&gt;
  &lt;li&gt;Non-equi-join filters in JOIN conditions&lt;/li&gt;
  &lt;li&gt;Modulus operation&lt;/li&gt;
  &lt;li&gt;Support group by column positions&lt;/li&gt;
  &lt;li&gt;Added constant folding query optimizer&lt;/li&gt;
  &lt;li&gt;Hash partitioned aggregation&lt;/li&gt;
  &lt;li&gt;Added &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;random&lt;/code&gt; SQL function&lt;/li&gt;
  &lt;li&gt;Implemented count distinct for floats and dictionary types&lt;/li&gt;
  &lt;li&gt;Re-exported arrow and parquet crates in Datafusion&lt;/li&gt;
  &lt;li&gt;General row group pruning logic that’s agnostic to storage format&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;how-to-get-involved&quot;&gt;How to Get Involved&lt;/h1&gt;

&lt;p&gt;If you are interested in contributing to DataFusion, we would love to have you! You 
can help by trying out DataFusion on some of your own data and projects and filing bug reports and helping to 
improve the documentation, or contribute to the documentation, tests or code. A list of open issues suitable for 
beginners is &lt;a href=&quot;https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22&quot;&gt;here&lt;/a&gt; 
and the full list is &lt;a href=&quot;https://github.com/apache/arrow-datafusion/issues&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</content><author><name>pmc</name></author><category term="release" /><summary type="html">The Apache Arrow team is pleased to announce the DataFusion 5.0.0 release. This covers 4 months of development work and includes 211 commits from the following 31 distinct contributors. $ git shortlog -sn 4.0.0..5.0.0 datafusion datafusion-cli datafusion-examples 61 Jiayu Liu 47 Andrew Lamb 27 Daniël Heres 13 QP Hou 13 Andy Grove 4 Javier Goday 4 sathis 3 Ruan Pearce-Authers 3 Raphael Taylor-Davies 3 Jorge Leitao 3 Cui Wenzheng 3 Mike Seddon 3 Edd Robinson 2 思维 2 Liang-Chi Hsieh 2 Michael Lu 2 Parth Sarthy 2 Patrick More 2 Rich 1 Charlie Evans 1 Gang Liao 1 Agata Naomichi 1 Ritchie Vink 1 Evan Chan 1 Ruihang Xia 1 Todd Treece 1 Yichen Wang 1 baishen 1 Nga Tran 1 rdettai 1 Marco Neumann The release notes below are not exhaustive and only expose selected highlights of the release. Many other bug fixes and improvements have been made: we refer you to the complete changelog. Performance There have been numerous performance improvements in this release. The following chart shows the relative performance of individual TPC-H queries compared to the previous release. TPC-H @ scale factor 100, in parquet format. Concurrency 24. We also extended support for more TPC-H queries: q7, q8, q9 and q13 are running successfully in DataFusion 5.0. New Features Initial support for SQL-99 Analytics (WINDOW functions) Improved JOIN support: cross join, semi-join, anti join, and fixes to null handling Improved EXPLAIN support Initial implementation of metrics in the physical plan Support for SELECT DISTINCT Support for Json and NDJson formatted inputs Query column with relations Added more datetime related functions: now, date_trunc, to_timestamp_millis, to_timestamp_micros, to_timestamp_seconds Streaming Dataframe.collect Support table column aliases Answer count(*), min() and max() queries using only statistics Non-equi-join filters in JOIN conditions Modulus operation Support group by column positions Added constant folding query optimizer Hash partitioned aggregation Added random SQL function Implemented count distinct for floats and dictionary types Re-exported arrow and parquet crates in Datafusion General row group pruning logic that’s agnostic to storage format How to Get Involved If you are interested in contributing to DataFusion, we would love to have you! You can help by trying out DataFusion on some of your own data and projects and filing bug reports and helping to improve the documentation, or contribute to the documentation, tests or code. A list of open issues suitable for beginners is here and the full list is here.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arrow.apache.org/img/arrow.png" /><media:content medium="image" url="https://arrow.apache.org/img/arrow.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow 5.0.0 Release</title><link href="https://arrow.apache.org/blog/2021/07/29/5.0.0-release/" rel="alternate" type="text/html" title="Apache Arrow 5.0.0 Release" /><published>2021-07-29T02:00:00-04:00</published><updated>2021-07-29T02:00:00-04:00</updated><id>https://arrow.apache.org/blog/2021/07/29/5.0.0-release</id><content type="html" xml:base="https://arrow.apache.org/blog/2021/07/29/5.0.0-release/">&lt;!--

--&gt;

&lt;p&gt;The Apache Arrow team is pleased to announce the 5.0.0 release. This covers
3 months of development work and includes &lt;strong&gt;684 commits&lt;/strong&gt; from
&lt;a href=&quot;/release/5.0.0.html#contributors&quot;&gt;&lt;strong&gt;99 distinct contributors&lt;/strong&gt;&lt;/a&gt; in 2 repositories. See the Install Page to
learn how to get the libraries for your platform.&lt;/p&gt;

&lt;p&gt;The release notes below are not exhaustive and only expose selected highlights
of the release. Many other bugfixes and improvements have been made: we refer
you to the complete changelogs for the &lt;a href=&quot;/release/5.0.0.html#changelog&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;apache/arrow&lt;/code&gt;&lt;/a&gt; and
&lt;a href=&quot;https://github.com/apache/arrow-rs/blob/5.0.0/CHANGELOG.md&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;apache/arrow-rs&lt;/code&gt;&lt;/a&gt; repositories.&lt;/p&gt;

&lt;h2 id=&quot;community&quot;&gt;Community&lt;/h2&gt;

&lt;p&gt;Since the 4.0.0 release, Daniël Heres, Kazuaki Ishizaki, Dominik Moritz, and Weston Pace
have been invited as committers to Arrow,
and Benjamin Kietzman and David Li have joined the Project Management Committee
(PMC). Thank you for all of your contributions!&lt;/p&gt;

&lt;h2 id=&quot;columnar-format-notes&quot;&gt;Columnar Format Notes&lt;/h2&gt;

&lt;p&gt;Official IANA Media types (MIME types) have been registered for Apache
Arrow IPC protocol data, both &lt;a href=&quot;/docs/format/Columnar.html#ipc-streaming-format&quot;&gt;stream&lt;/a&gt;
and &lt;a href=&quot;/docs/format/Columnar.html#ipc-file-format&quot;&gt;file&lt;/a&gt; variants:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.iana.org/assignments/media-types/application/vnd.apache.arrow.stream&quot;&gt;https://www.iana.org/assignments/media-types/application/vnd.apache.arrow.stream&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.iana.org/assignments/media-types/application/vnd.apache.arrow.file&quot;&gt;https://www.iana.org/assignments/media-types/application/vnd.apache.arrow.file&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We recommend &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.arrow&lt;/code&gt; as the IPC file format file extension and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.arrows&lt;/code&gt; for
the IPC streaming format file extension.&lt;/p&gt;

&lt;h2 id=&quot;arrow-flight-rpc-notes&quot;&gt;Arrow Flight RPC notes&lt;/h2&gt;

&lt;p&gt;The Go implementation now supports custom metadata and middleware, and has
been added to integration testing.&lt;/p&gt;

&lt;p&gt;In Python, some operations can now be interrupted via Control-C.&lt;/p&gt;

&lt;h2 id=&quot;c-notes&quot;&gt;C++ notes&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MakeArrayFromScalar&lt;/code&gt; now works for fixed-size binary types (&lt;a href=&quot;https://issues.apache.org/jira/browse/ARROW-13321&quot;&gt;ARROW-13321&lt;/a&gt;).&lt;/p&gt;

&lt;h3 id=&quot;compute-layer&quot;&gt;Compute layer&lt;/h3&gt;

&lt;p&gt;The following &lt;a href=&quot;/docs/cpp/compute.html&quot;&gt;compute functions&lt;/a&gt;
were added:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;aggregations: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;index&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;scalar arithmetic and math functions: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;abs&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;abs_checked&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;acos&lt;/code&gt;,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;acos_checked&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;asin&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;asin_checked&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;atan&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;atan2&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ceil&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cos&lt;/code&gt;,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cos_checked&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;floor&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ln&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ln_checked&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;log10&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;log10_checked&lt;/code&gt;,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;log1p&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;log1p_checked&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;log2&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;log2_checked&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;negate&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;negate_checked&lt;/code&gt;,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sign&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sin&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sin_checked&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tan&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tan_checked&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;trunc&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;scalar bitwise functions: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bit_wise_and&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bit_wise_not&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bit_wise_or&lt;/code&gt;,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bit_wise_xor&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;shift_left&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;shift_left_checked&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;shift_right&lt;/code&gt;,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;shift_right_checked&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;scalar string functions: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ascii_center&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ascii_lpad&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ascii_reverse&lt;/code&gt;,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ascii_rpad&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;binary_join&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;binary_join_element_wise&lt;/code&gt;,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;binary_replace_slice&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;count_substring&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;count_substring_regex&lt;/code&gt;,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ends_with&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;find_substring&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;find_substring_regex&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;match_like&lt;/code&gt;,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;split_pattern_regex&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;starts_with&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;utf8_center&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;utf8_lpad&lt;/code&gt;,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;utf8_replace_slice&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;utf8_rpad&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;utf8_reverse&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;utf8_slice_codepoints&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;scalar temporal functions: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;day&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;day_of_week&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;day_of_year&lt;/code&gt;,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;iso_calendar&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;iso_week&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;iso_year&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hour&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;microsecond&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;millisecond&lt;/code&gt;,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;minute&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;month&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nanosecond&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quarter&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;second&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subsecond&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;year&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;other scalar functions: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;case_when&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;coalesce&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;if_else&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;is_finite&lt;/code&gt;,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;is_inf&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;is_nan&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_element_wise&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min_element_wise&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;make_struct&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;vector functions: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replace_with_mask&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Duplicates are now allowed in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SetLookupOptions::value_set&lt;/code&gt; (&lt;a href=&quot;https://issues.apache.org/jira/browse/ARROW-12554&quot;&gt;ARROW-12554&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Decimal types are now supported by some basic arithmetic functions (&lt;a href=&quot;https://issues.apache.org/jira/browse/ARROW-12074&quot;&gt;ARROW-12074&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;take&lt;/code&gt; function now supports dense unions (&lt;a href=&quot;https://issues.apache.org/jira/browse/ARROW-13005&quot;&gt;ARROW-13005&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;It is now possible to cast between dictionary types with different index
types (&lt;a href=&quot;https://issues.apache.org/jira/browse/ARROW-11673&quot;&gt;ARROW-11673&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Sorting is now implemented for boolean input (&lt;a href=&quot;https://issues.apache.org/jira/browse/ARROW-12016&quot;&gt;ARROW-12016&lt;/a&gt;).&lt;/p&gt;

&lt;h3 id=&quot;csv&quot;&gt;CSV&lt;/h3&gt;

&lt;p&gt;The streaming CSV reader can now take some advantage of multiple threads (&lt;a href=&quot;https://issues.apache.org/jira/browse/ARROW-11889&quot;&gt;ARROW-11889&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;The CSV reader tries to make its errors more informative by adding the
row number when it is known, i.e. when parallel reading is disabled (&lt;a href=&quot;https://issues.apache.org/jira/browse/ARROW-12675&quot;&gt;ARROW-12675&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;A new option &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ReaderOptions::skip_rows_after_names&lt;/code&gt; allows skipping a number
of rows &lt;em&gt;after&lt;/em&gt; reading the column names (as opposed to
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ReaderOptions::skip_rows&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;Quoted strings can now be treated as always non-null (&lt;a href=&quot;https://issues.apache.org/jira/browse/ARROW-10115&quot;&gt;ARROW-10115&lt;/a&gt;).&lt;/p&gt;

&lt;h3 id=&quot;dataset-layer&quot;&gt;Dataset layer&lt;/h3&gt;

&lt;p&gt;The asynchronous scanner introduced in 4.0.0 has been improved with truly 
asynchronous readers implemented for CSV, Parquet, and IPC file formats and 
file-level parallelism added.  This mode is controlled by a flag &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;use_async&lt;/code&gt; that
can be passed into methods which scan a dataset.  Setting this flag to True
will have significant improvements on filesystems with high latency or parallel
reads (e.g. S3).&lt;/p&gt;

&lt;p&gt;A CountRows method has been added to count rows matching a predicate; where
possible, this will use metadata in files instead of reading the data itself.&lt;/p&gt;

&lt;p&gt;CSV datasets can now be written, and when reading a CSV dataset, explicit types can
now be specified for a subset of columns while allowing the rest to still be inferred.&lt;/p&gt;

&lt;h3 id=&quot;io-and-filesystem-layer&quot;&gt;IO and Filesystem layer&lt;/h3&gt;

&lt;p&gt;The I/O thread pool size can now be adjusted at runtime (&lt;a href=&quot;https://issues.apache.org/jira/browse/ARROW-12760&quot;&gt;ARROW-12760&lt;/a&gt;).
The default size remains 8 threads.&lt;/p&gt;

&lt;p&gt;Streams now can have auxiliary metadata, depending on the backend.  This
has been implemented for the S3 filesystems, where a couple metadata
keys are supported such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Content-Type&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ACL&lt;/code&gt; (&lt;a href=&quot;https://issues.apache.org/jira/browse/ARROW-11161&quot;&gt;ARROW-11161&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/ARROW-12719&quot;&gt;ARROW-12719&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;The HadoopFileSystem implementation now implements the FileSystem abstraction
more faithfully (&lt;a href=&quot;https://issues.apache.org/jira/browse/ARROW-12790&quot;&gt;ARROW-12790&lt;/a&gt;).&lt;/p&gt;

&lt;h3 id=&quot;parquet&quot;&gt;Parquet&lt;/h3&gt;

&lt;p&gt;The new LZ4_RAW compression scheme was implemented (PARQUET-1998).
Unlike the legacy LZ4 compression scheme, it is defined unambiguously
and should provide better portability once other Parquet implementations
catch up.&lt;/p&gt;

&lt;h2 id=&quot;go-notes&quot;&gt;Go notes&lt;/h2&gt;

&lt;h3 id=&quot;flight&quot;&gt;Flight&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Flight Client and Server now support Custom Metadata through the functions &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;flight.NewClientWithMiddleware&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;flight.NewServerWithMiddleware&lt;/code&gt;. Functions
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;flight.NewFlightClient&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;flight.NewFlightServer&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;flight.CreateServerBearerTokenAuthInterceptors&lt;/code&gt; have been deprecated in favor of using the new middleware. &lt;a href=&quot;https://github.com/apache/arrow/pull/10633&quot;&gt;#10633&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Flight Client &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AuthHandler&lt;/code&gt; no longer overwrites outgoing metadata, correctly appending new metadata without overwriting existing metadata &lt;a href=&quot;https://github.com/apache/arrow/pull/10297&quot;&gt;#10297&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Flight AppMetadata field is now exposed both for Reading and Writing via &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;flight.Reader#LatestAppMetadata()&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;flight.Writer#WriteWithAppMetadata&lt;/code&gt; functions &lt;a href=&quot;https://github.com/apache/arrow/pull/10142&quot;&gt;#10142&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;other-enhancements&quot;&gt;Other enhancements&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/arrow/pull/10106&quot;&gt;Map&lt;/a&gt; and &lt;a href=&quot;https://github.com/apache/arrow/pull/10203&quot;&gt;Extension&lt;/a&gt; Datatypes are now implemented for Arrow Arrays&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/arrow/pull/10071&quot;&gt;Schema package&lt;/a&gt; and first part of &lt;a href=&quot;https://github.com/apache/arrow/pull/10379&quot;&gt;Encoding package&lt;/a&gt; added for Golang Parquet Implementation&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;java-notes&quot;&gt;Java notes&lt;/h2&gt;

&lt;p&gt;Highlighted improvements and fixes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Improved support for extension types using a complex storage type, e.g. struct, map or union. These can now extend
the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ExtensionTypeVector&lt;/code&gt; base class.&lt;/li&gt;
  &lt;li&gt;Union vectors now extend &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AbstractContainerVector&lt;/code&gt; to be consistent with other vectors.&lt;/li&gt;
  &lt;li&gt;Guava dependency updated to 30.1.1&lt;/li&gt;
  &lt;li&gt;Memory leak fixed if an exception occurs when reading IPC messages from a channel. &lt;a href=&quot;https://github.com/apache/arrow/pull/10423&quot;&gt;#10423&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Flight error metadata is now propagated to the client. &lt;a href=&quot;https://github.com/apache/arrow/pull/10370&quot;&gt;#10370&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;JDBC adapter now preserves nullability. &lt;a href=&quot;https://github.com/apache/arrow/pull/10285&quot;&gt;#10285&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;The memory rounding policy is respected when allocating vector buffers. This helps saving memory space. &lt;a href=&quot;https://github.com/apache/arrow/pull/10576&quot;&gt;#10576&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;API compatibility changes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Complex vectors now return covariant types from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;getObject(int)&lt;/code&gt;. &lt;a href=&quot;https://github.com/apache/arrow/pull/9964&quot;&gt;#9964&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;javascript-notes&quot;&gt;JavaScript notes&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Tables do not extend DataFrames anymore. This enables smaller bundles. &lt;a href=&quot;https://github.com/apache/arrow/pull/10277&quot;&gt;#10277&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Arrow uses closure compiler for all UMD bundles, making them smaller. &lt;a href=&quot;https://github.com/apache/arrow/pull/10281&quot;&gt;#10281&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;The npm package now comes with declaration maps for better navigation from types to source code. &lt;a href=&quot;https://github.com/apache/arrow/pull/10673&quot;&gt;#10673&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Updated dependencies and improvements to the code.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;python-notes&quot;&gt;Python notes&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Datasets can now scan files asynchronously when the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;use_async=True&lt;/code&gt; option is provided to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Dataset.scanner&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Dataset.to_table&lt;/code&gt;, or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Dataset.to_batches&lt;/code&gt; methods. This should provide better performance in environments where I/O can be slow, such as with remote sources.&lt;/li&gt;
  &lt;li&gt;Arrow now provides builtin support for writing CSV files through &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pyarrow.csv.write_csv&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Wheels for Apple M1 Macs are now provided.&lt;/li&gt;
  &lt;li&gt;Many new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pyarrow.compute&lt;/code&gt; functions are available (see the C++ notes above
for more details), and introspection of the functions was improved so that
they look more like standard Python functions.&lt;/li&gt;
  &lt;li&gt;It is now possible to access ORC file metadata from Python &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORCFile&lt;/code&gt; objects&lt;/li&gt;
  &lt;li&gt;Building a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StructArray&lt;/code&gt; now accepts a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mask&lt;/code&gt; like other arrays&lt;/li&gt;
  &lt;li&gt;Many updates and fixes for the documentation&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;r-notes&quot;&gt;R notes&lt;/h2&gt;

&lt;p&gt;In this release, we’ve more than doubled the number of functions you can call on Arrow Datasets inside &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dplyr::filter()&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mutate()&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arrange()&lt;/code&gt;, including many more string, datetime, and math functions. You can also write Datasets to CSV files, in addition to Parquet and Feather. We’ve also deepened support for the Arrow C interface, which is used in the Python interface and allows integration with other projects, such as DuckDB.&lt;/p&gt;

&lt;p&gt;For more on what’s in the 5.0.0 R package, see the &lt;a href=&quot;/docs/r/news/&quot;&gt;R changelog&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;ruby-and-c-glib-notes&quot;&gt;Ruby and C GLib notes&lt;/h2&gt;

&lt;p&gt;Apache Arrow Flight support is started. But &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ListFlights&lt;/code&gt; is only supported for now. More features will be implemented in the next major release.&lt;/p&gt;

&lt;h3 id=&quot;ruby&quot;&gt;Ruby&lt;/h3&gt;

&lt;p&gt;You need gobject-introspection gem 3.4.5 or later to implement your Apache Arrow Flight server. If you only use Apache Arrow Flight client, gobject-introspection gem 3.4.5 or later isn’t required.&lt;/p&gt;

&lt;p&gt;Here are highlighted improvements:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Compute functions accept raw Ruby objects such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;true&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Integer&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Array&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;String&lt;/code&gt;:&lt;/p&gt;

    &lt;div class=&quot;language-ruby highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;add_function&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Arrow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;Function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;add&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Not shortcut version&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;augend&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Arrow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;Int8Array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;addend&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Arrow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;Int8Scalar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
  &lt;span class=&quot;no&quot;&gt;Arrow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;ArrayDatum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;augend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;no&quot;&gt;Arrow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;ScalarDatum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;addend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;add_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;to_a&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# =&amp;gt; [6, 7, 8]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Shortcut version&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;add_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;to_a&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# =&amp;gt; [6, 7, 8]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Arrow::PrimaryArray&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Arrow::Buffer&lt;/code&gt; can be used as MemoryView that is added in Ruby 3.0.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are some backward incompatible changes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Arrow::CountOptions&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Arrow::CountMode&lt;/code&gt; are removed. Use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Arrow::ScalarAggregateOptions&lt;/code&gt; instead.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;c-glib&quot;&gt;C GLib&lt;/h3&gt;

&lt;p&gt;There are some backward incompatible changes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GArrowCountOptions&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GArrowCountMode&lt;/code&gt; are removed. Use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GArrowScalarAggregateOptions&lt;/code&gt; instead.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;garrow_array_equal_range()&lt;/code&gt; requires &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GArrowEqualOptions&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Prefix in arrow-dataset-glib is changed to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gadataset_&lt;/code&gt;/&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GADATASET_&lt;/code&gt; from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gad_&lt;/code&gt;/&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GAD_&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GADScanOptions&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GADScanTask&lt;/code&gt;  and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GADInMemoryScanTask&lt;/code&gt; are removed. Use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gadataset_begin_scan()&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gadataset_to_table()&lt;/code&gt; instead.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GArrowCompareOptions&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GArrowCompareOperator&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;garrow_*_array_compare()&lt;/code&gt; are removed. Use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;equal&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;not_equal&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;less_than&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;less_than_equal&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;greater_than&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;greater_than_equal&lt;/code&gt; compute functions directly instead.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;rust-notes&quot;&gt;Rust notes&lt;/h2&gt;

&lt;p&gt;The Rust projects have moved to separate repositories outside the
main Arrow monorepo. For notes on the 5.0.0 release of the Rust
implementation, see the &lt;a href=&quot;https://github.com/apache/arrow-rs/blob/5.0.0/CHANGELOG.md&quot;&gt;Arrow Rust changelog&lt;/a&gt; and the
&lt;a href=&quot;/blog/2021/07/29/5.0.0-rs-release/&quot;&gt;Apache Arrow Rust 5.0.0 Release blog post&lt;/a&gt;.&lt;/p&gt;</content><author><name>pmc</name></author><category term="release" /><summary type="html">The Apache Arrow team is pleased to announce the 5.0.0 release. This covers 3 months of development work and includes 684 commits from 99 distinct contributors in 2 repositories. See the Install Page to learn how to get the libraries for your platform. The release notes below are not exhaustive and only expose selected highlights of the release. Many other bugfixes and improvements have been made: we refer you to the complete changelogs for the apache/arrow and apache/arrow-rs repositories. Community Since the 4.0.0 release, Daniël Heres, Kazuaki Ishizaki, Dominik Moritz, and Weston Pace have been invited as committers to Arrow, and Benjamin Kietzman and David Li have joined the Project Management Committee (PMC). Thank you for all of your contributions! Columnar Format Notes Official IANA Media types (MIME types) have been registered for Apache Arrow IPC protocol data, both stream and file variants: https://www.iana.org/assignments/media-types/application/vnd.apache.arrow.stream https://www.iana.org/assignments/media-types/application/vnd.apache.arrow.file We recommend .arrow as the IPC file format file extension and .arrows for the IPC streaming format file extension. Arrow Flight RPC notes The Go implementation now supports custom metadata and middleware, and has been added to integration testing. In Python, some operations can now be interrupted via Control-C. C++ notes MakeArrayFromScalar now works for fixed-size binary types (ARROW-13321). Compute layer The following compute functions were added: aggregations: index scalar arithmetic and math functions: abs, abs_checked, acos, acos_checked, asin, asin_checked, atan, atan2, ceil, cos, cos_checked, floor, ln, ln_checked, log10, log10_checked, log1p, log1p_checked, log2, log2_checked, negate, negate_checked, sign, sin, sin_checked, tan, tan_checked, trunc scalar bitwise functions: bit_wise_and, bit_wise_not, bit_wise_or, bit_wise_xor, shift_left, shift_left_checked, shift_right, shift_right_checked scalar string functions: ascii_center, ascii_lpad, ascii_reverse, ascii_rpad, binary_join, binary_join_element_wise, binary_replace_slice, count_substring, count_substring_regex, ends_with, find_substring, find_substring_regex, match_like, split_pattern_regex, starts_with, utf8_center, utf8_lpad, utf8_replace_slice, utf8_rpad, utf8_reverse, utf8_slice_codepoints scalar temporal functions: day, day_of_week, day_of_year, iso_calendar, iso_week, iso_year, hour, microsecond, millisecond, minute, month, nanosecond, quarter, second, subsecond, year other scalar functions: case_when, coalesce, if_else, is_finite, is_inf, is_nan, max_element_wise, min_element_wise, make_struct vector functions: replace_with_mask Duplicates are now allowed in SetLookupOptions::value_set (ARROW-12554). Decimal types are now supported by some basic arithmetic functions (ARROW-12074). The take function now supports dense unions (ARROW-13005). It is now possible to cast between dictionary types with different index types (ARROW-11673). Sorting is now implemented for boolean input (ARROW-12016). CSV The streaming CSV reader can now take some advantage of multiple threads (ARROW-11889). The CSV reader tries to make its errors more informative by adding the row number when it is known, i.e. when parallel reading is disabled (ARROW-12675). A new option ReaderOptions::skip_rows_after_names allows skipping a number of rows after reading the column names (as opposed to ReaderOptions::skip_rows). Quoted strings can now be treated as always non-null (ARROW-10115). Dataset layer The asynchronous scanner introduced in 4.0.0 has been improved with truly asynchronous readers implemented for CSV, Parquet, and IPC file formats and file-level parallelism added. This mode is controlled by a flag use_async that can be passed into methods which scan a dataset. Setting this flag to True will have significant improvements on filesystems with high latency or parallel reads (e.g. S3). A CountRows method has been added to count rows matching a predicate; where possible, this will use metadata in files instead of reading the data itself. CSV datasets can now be written, and when reading a CSV dataset, explicit types can now be specified for a subset of columns while allowing the rest to still be inferred. IO and Filesystem layer The I/O thread pool size can now be adjusted at runtime (ARROW-12760). The default size remains 8 threads. Streams now can have auxiliary metadata, depending on the backend. This has been implemented for the S3 filesystems, where a couple metadata keys are supported such as Content-Type and ACL (ARROW-11161, ARROW-12719). The HadoopFileSystem implementation now implements the FileSystem abstraction more faithfully (ARROW-12790). Parquet The new LZ4_RAW compression scheme was implemented (PARQUET-1998). Unlike the legacy LZ4 compression scheme, it is defined unambiguously and should provide better portability once other Parquet implementations catch up. Go notes Flight Flight Client and Server now support Custom Metadata through the functions flight.NewClientWithMiddleware and flight.NewServerWithMiddleware. Functions flight.NewFlightClient, flight.NewFlightServer, flight.CreateServerBearerTokenAuthInterceptors have been deprecated in favor of using the new middleware. #10633 Flight Client AuthHandler no longer overwrites outgoing metadata, correctly appending new metadata without overwriting existing metadata #10297 Flight AppMetadata field is now exposed both for Reading and Writing via flight.Reader#LatestAppMetadata() and flight.Writer#WriteWithAppMetadata functions #10142 Other enhancements Map and Extension Datatypes are now implemented for Arrow Arrays Schema package and first part of Encoding package added for Golang Parquet Implementation Java notes Highlighted improvements and fixes: Improved support for extension types using a complex storage type, e.g. struct, map or union. These can now extend the ExtensionTypeVector base class. Union vectors now extend AbstractContainerVector to be consistent with other vectors. Guava dependency updated to 30.1.1 Memory leak fixed if an exception occurs when reading IPC messages from a channel. #10423 Flight error metadata is now propagated to the client. #10370 JDBC adapter now preserves nullability. #10285 The memory rounding policy is respected when allocating vector buffers. This helps saving memory space. #10576 API compatibility changes: Complex vectors now return covariant types from getObject(int). #9964 JavaScript notes Tables do not extend DataFrames anymore. This enables smaller bundles. #10277 Arrow uses closure compiler for all UMD bundles, making them smaller. #10281 The npm package now comes with declaration maps for better navigation from types to source code. #10673 Updated dependencies and improvements to the code. Python notes Datasets can now scan files asynchronously when the use_async=True option is provided to Dataset.scanner, Dataset.to_table, or Dataset.to_batches methods. This should provide better performance in environments where I/O can be slow, such as with remote sources. Arrow now provides builtin support for writing CSV files through pyarrow.csv.write_csv Wheels for Apple M1 Macs are now provided. Many new pyarrow.compute functions are available (see the C++ notes above for more details), and introspection of the functions was improved so that they look more like standard Python functions. It is now possible to access ORC file metadata from Python ORCFile objects Building a StructArray now accepts a mask like other arrays Many updates and fixes for the documentation R notes In this release, we’ve more than doubled the number of functions you can call on Arrow Datasets inside dplyr::filter(), mutate(), and arrange(), including many more string, datetime, and math functions. You can also write Datasets to CSV files, in addition to Parquet and Feather. We’ve also deepened support for the Arrow C interface, which is used in the Python interface and allows integration with other projects, such as DuckDB. For more on what’s in the 5.0.0 R package, see the R changelog. Ruby and C GLib notes Apache Arrow Flight support is started. But ListFlights is only supported for now. More features will be implemented in the next major release. Ruby You need gobject-introspection gem 3.4.5 or later to implement your Apache Arrow Flight server. If you only use Apache Arrow Flight client, gobject-introspection gem 3.4.5 or later isn’t required. Here are highlighted improvements: Compute functions accept raw Ruby objects such as true, Integer, Array and String: add_function = Arrow::Function.find(&quot;add&quot;) # Not shortcut version augend = Arrow::Int8Array.new([1, 2, 3]) addend = Arrow::Int8Scalar.new(5) args = [ Arrow::ArrayDatum.new(augend), Arrow::ScalarDatum.new(addend), ] add_function.execute(args).value.to_a # =&amp;gt; [6, 7, 8] # Shortcut version add_function.execute([[1, 2, 3], 5]).value.to_a # =&amp;gt; [6, 7, 8] Arrow::PrimaryArray and Arrow::Buffer can be used as MemoryView that is added in Ruby 3.0. There are some backward incompatible changes: Arrow::CountOptions and Arrow::CountMode are removed. Use Arrow::ScalarAggregateOptions instead. C GLib There are some backward incompatible changes: GArrowCountOptions and GArrowCountMode are removed. Use GArrowScalarAggregateOptions instead. garrow_array_equal_range() requires GArrowEqualOptions. Prefix in arrow-dataset-glib is changed to gadataset_/GADATASET_ from gad_/GAD_. GADScanOptions, GADScanTask and GADInMemoryScanTask are removed. Use gadataset_begin_scan() or gadataset_to_table() instead. GArrowCompareOptions, GArrowCompareOperator and garrow_*_array_compare() are removed. Use equal, not_equal, less_than, less_than_equal, greater_than and greater_than_equal compute functions directly instead. Rust notes The Rust projects have moved to separate repositories outside the main Arrow monorepo. For notes on the 5.0.0 release of the Rust implementation, see the Arrow Rust changelog and the Apache Arrow Rust 5.0.0 Release blog post.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arrow.apache.org/img/arrow.png" /><media:content medium="image" url="https://arrow.apache.org/img/arrow.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow Rust 5.0.0 Release</title><link href="https://arrow.apache.org/blog/2021/07/29/5.0.0-rs-release/" rel="alternate" type="text/html" title="Apache Arrow Rust 5.0.0 Release" /><published>2021-07-29T00:00:00-04:00</published><updated>2021-07-29T00:00:00-04:00</updated><id>https://arrow.apache.org/blog/2021/07/29/5.0.0-rs-release</id><content type="html" xml:base="https://arrow.apache.org/blog/2021/07/29/5.0.0-rs-release/">&lt;!--

--&gt;

&lt;p&gt;We recently released the 5.0.0 Rust version of &lt;a href=&quot;https://arrow.apache.org/&quot;&gt;Apache Arrow&lt;/a&gt; which coincides with the &lt;a href=&quot;https://arrow.apache.org/release/5.0.0.html&quot;&gt;Arrow 5.0.0 release&lt;/a&gt;. This post highlights some of the improvements in the Rust implementation. The full changelog can be found &lt;a href=&quot;https://github.com/apache/arrow-rs/blob/5.0.0/CHANGELOG.md&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;!--
(arrow_dev) alamb@MacBook-Pro:~/Software/arrow-rs$ git log --pretty=oneline 4.0.0..5.0.0 | wc -l
     161
(arrow_dev) alamb@MacBook-Pro:~/Software/arrow-rs$ git shortlog -sn 4.0.0..5.0.0 | wc -l
      35 // but Jorge is double counted
--&gt;

&lt;p&gt;The Rust Arrow implementation would not be possible without the wonderful work and support of our community, and the 5.0.0 release is no exception. It includes 161 commits from 34 individual contributors, many of them with their first contribution. Thank you all very much.&lt;/p&gt;

&lt;h1 id=&quot;arrow&quot;&gt;Arrow&lt;/h1&gt;
&lt;p&gt;Feature-wise, this release adds:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;A &lt;a href=&quot;https://github.com/apache/arrow-rs/pull/424&quot;&gt;new kernel&lt;/a&gt; which lexicographically partitions points.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/arrow-rs/pull/439&quot;&gt;Expanded support&lt;/a&gt; for the FFI/&lt;a href=&quot;https://arrow.apache.org/docs/format/CDataInterface.html&quot;&gt;C data interface&lt;/a&gt;, easing integration with the broader Arrow ecosystem&lt;/li&gt;
  &lt;li&gt;Usability enhancements for creating and manipulating &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RecordBatch&lt;/code&gt;es.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/arrow-rs/pull/377&quot;&gt;Improved usability&lt;/a&gt; for Arrow Flight’s API.&lt;/li&gt;
  &lt;li&gt;Slimmer dependency stack when default features are disabled&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We continue to leverage the Rust ecosystem to deliver reliable and performant code. We made significant progress towards running the Rust test suite under the &lt;a href=&quot;https://github.com/rust-lang/miri&quot;&gt;MIRI checker&lt;/a&gt; (a sort of valgrind for Rust) for memory access violations, and we expect it to be fully enabled in CI for the 5.1.0 release.&lt;/p&gt;

&lt;p&gt;Of course, this release also contains bug fixes, performance improvements, and improved documentation examples. For the full list of changes, please consult the &lt;a href=&quot;https://github.com/apache/arrow-rs/blob/5.0.0/CHANGELOG.md&quot;&gt;changelog&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;parquet&quot;&gt;Parquet&lt;/h1&gt;
&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parquet-derive&lt;/code&gt; crate now automatically derives the required parquet schema, and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parquet&lt;/code&gt; crate had several bug fixes and enhancements.&lt;/p&gt;

&lt;h1 id=&quot;more-frequent-releases&quot;&gt;More Frequent Releases&lt;/h1&gt;
&lt;p&gt;Arrow releases major versions every three months. The Rust implementation has been experimenting with releasing minor version updates to speed the flow of new features and fixes. By implementing a new development process, as described in &lt;a href=&quot;https://arrow.apache.org/blog/2021/05/04/rust-dev-workflow/&quot;&gt;A New Development Workflow for Arrow’s Rust Implementation&lt;/a&gt; we have successfully created 4 minor releases on the 4.x.x line every other week without any reports of breakage.&lt;/p&gt;

&lt;p&gt;You can always find the latest releases on crates.io: &lt;a href=&quot;https://crates.io/crates/arrow&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arrow&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;https://crates.io/crates/parquet&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parquet&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;https://crates.io/crates/arrow-flight&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arrow-flight&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;https://crates.io/crates/parquet-derive&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parquet-derive&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;datafusion--ballista&quot;&gt;DataFusion &amp;amp; Ballista&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.rs/datafusion/4.0.0/datafusion/&quot;&gt;DataFusion&lt;/a&gt; is an in-memory query engine with DataFrame and SQL APIs, built on top of Arrow. Ballista is a distributed compute platform. These projects are now in their &lt;a href=&quot;https://github.com/apache/arrow-datafusion&quot;&gt;own repository&lt;/a&gt;, and are no longer released in lock-step with Arrow. Expect further news in this area soon.&lt;/p&gt;

&lt;h1 id=&quot;roadmap-for-600-and-beyond&quot;&gt;Roadmap for 6.0.0 and Beyond&lt;/h1&gt;
&lt;p&gt;Here are some of the initiatives that contributors are currently working on for future releases:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Improved performance of compute kernels&lt;/li&gt;
  &lt;li&gt;Date/time/timestamp/interval compute kernels&lt;/li&gt;
  &lt;li&gt;MapArray support&lt;/li&gt;
  &lt;li&gt;Preparations for removing the use of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;unsafe&lt;/code&gt; to make arrow faster and more secure – see the &lt;a href=&quot;https://lists.apache.org/thread.html/recac1f6dc982bab2923f8fb6992e2d4c927f46daff5f03ed6c4de19c%40%3Cdev.arrow.apache.org%3E&quot;&gt;mailing list&lt;/a&gt; discussion for more details.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;contributors-to-500&quot;&gt;Contributors to 5.0.0:&lt;/h1&gt;
&lt;p&gt;Again, thank you to all the contributors for this release. Here is the raw git listing:&lt;/p&gt;

&lt;!--
(arrow_dev) alamb@MacBook-Pro:~/Software/arrow-rs$ git shortlog -sn 4.0.0..5.0.0
.. list below ..

Note I combined two distinct names for Jorge
--&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    28  Jorge Leitao
    27  Andrew Lamb
    15  Jiayu Liu
    12  Ritchie Vink
    10  Wakahisa
     8  Raphael Taylor-Davies
     6  Daniël Heres
     5  Andy Grove
     5  Navin
     5  Jörn Horstmann
     4  Ádám Lippai
     4  Dominik Moritz
     4  Marco Neumann
     3  Roee Shlomo
     3  Michael Edwards
     2  Steven
     2  Krisztián Szűcs
     2  Gary Pennington
     1  Ben Chambers
     1  Max Meldrum
     1  Edd Robinson
     1  Gang Liao
     1  Chojan Shang
     1  Boaz
     1  Wes McKinney
     1  Yordan Pavlov
     1  baishen
     1  hulunbier
     1  kazuhiko kikuchi
     1  Dmitry Patsura
     1  Kornelijus Survila
     1  Laurent Mazare
     1  Manish Gill
     1  Marc van Heerden
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;how-to-get-involved&quot;&gt;How to Get Involved&lt;/h1&gt;
&lt;p&gt;If you are interested in contributing to the Rust implementation of Apache Arrow, we would love to have you! You can help by trying out Arrow on some of your own data and projects and filing bug reports and helping to improve the documentation, or contribute to the documentation, tests or code. A list of open issues suitable for beginners is &lt;a href=&quot;https://github.com/apache/arrow-rs/labels/good%20first%20issue&quot;&gt;here&lt;/a&gt; and the full list is &lt;a href=&quot;https://github.com/apache/arrow-rs/issues&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</content><author><name>pmc</name></author><category term="release" /><summary type="html">We recently released the 5.0.0 Rust version of Apache Arrow which coincides with the Arrow 5.0.0 release. This post highlights some of the improvements in the Rust implementation. The full changelog can be found here. The Rust Arrow implementation would not be possible without the wonderful work and support of our community, and the 5.0.0 release is no exception. It includes 161 commits from 34 individual contributors, many of them with their first contribution. Thank you all very much. Arrow Feature-wise, this release adds: A new kernel which lexicographically partitions points. Expanded support for the FFI/C data interface, easing integration with the broader Arrow ecosystem Usability enhancements for creating and manipulating RecordBatches. Improved usability for Arrow Flight’s API. Slimmer dependency stack when default features are disabled We continue to leverage the Rust ecosystem to deliver reliable and performant code. We made significant progress towards running the Rust test suite under the MIRI checker (a sort of valgrind for Rust) for memory access violations, and we expect it to be fully enabled in CI for the 5.1.0 release. Of course, this release also contains bug fixes, performance improvements, and improved documentation examples. For the full list of changes, please consult the changelog. Parquet The parquet-derive crate now automatically derives the required parquet schema, and the parquet crate had several bug fixes and enhancements. More Frequent Releases Arrow releases major versions every three months. The Rust implementation has been experimenting with releasing minor version updates to speed the flow of new features and fixes. By implementing a new development process, as described in A New Development Workflow for Arrow’s Rust Implementation we have successfully created 4 minor releases on the 4.x.x line every other week without any reports of breakage. You can always find the latest releases on crates.io: arrow, parquet, arrow-flight, and parquet-derive. DataFusion &amp;amp; Ballista DataFusion is an in-memory query engine with DataFrame and SQL APIs, built on top of Arrow. Ballista is a distributed compute platform. These projects are now in their own repository, and are no longer released in lock-step with Arrow. Expect further news in this area soon. Roadmap for 6.0.0 and Beyond Here are some of the initiatives that contributors are currently working on for future releases: Improved performance of compute kernels Date/time/timestamp/interval compute kernels MapArray support Preparations for removing the use of unsafe to make arrow faster and more secure – see the mailing list discussion for more details. Contributors to 5.0.0: Again, thank you to all the contributors for this release. Here is the raw git listing: 28 Jorge Leitao 27 Andrew Lamb 15 Jiayu Liu 12 Ritchie Vink 10 Wakahisa 8 Raphael Taylor-Davies 6 Daniël Heres 5 Andy Grove 5 Navin 5 Jörn Horstmann 4 Ádám Lippai 4 Dominik Moritz 4 Marco Neumann 3 Roee Shlomo 3 Michael Edwards 2 Steven 2 Krisztián Szűcs 2 Gary Pennington 1 Ben Chambers 1 Max Meldrum 1 Edd Robinson 1 Gang Liao 1 Chojan Shang 1 Boaz 1 Wes McKinney 1 Yordan Pavlov 1 baishen 1 hulunbier 1 kazuhiko kikuchi 1 Dmitry Patsura 1 Kornelijus Survila 1 Laurent Mazare 1 Manish Gill 1 Marc van Heerden How to Get Involved If you are interested in contributing to the Rust implementation of Apache Arrow, we would love to have you! You can help by trying out Arrow on some of your own data and projects and filing bug reports and helping to improve the documentation, or contribute to the documentation, tests or code. A list of open issues suitable for beginners is here and the full list is here.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arrow.apache.org/img/arrow.png" /><media:content medium="image" url="https://arrow.apache.org/img/arrow.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow 4.0.1 Release</title><link href="https://arrow.apache.org/blog/2021/06/19/4.0.1-release/" rel="alternate" type="text/html" title="Apache Arrow 4.0.1 Release" /><published>2021-06-19T00:00:00-04:00</published><updated>2021-06-19T00:00:00-04:00</updated><id>https://arrow.apache.org/blog/2021/06/19/4.0.1-release</id><content type="html" xml:base="https://arrow.apache.org/blog/2021/06/19/4.0.1-release/">&lt;!--

--&gt;

&lt;p&gt;The Apache Arrow team is pleased to announce the 4.0.1 release. This
release covers general bug fixes on the different implementations, notably
C++, R, Python and JavaScript.
The list is available &lt;a href=&quot;https://issues.apache.org/jira/issues/?jql=project%20%3D%20ARROW%20AND%20status%20%3D%20Resolved%20AND%20fixVersion%20%3D%204.0.1&quot;&gt;here&lt;/a&gt;, with the list of contributors &lt;a href=&quot;/release/4.0.1.html#contributors&quot;&gt;here&lt;/a&gt;
and changelog &lt;a href=&quot;/release/4.0.1.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As usual, see &lt;a href=&quot;/install/&quot;&gt;the install page&lt;/a&gt; for instructions on how to install it.&lt;/p&gt;</content><author><name>pmc</name></author><category term="release" /><summary type="html">The Apache Arrow team is pleased to announce the 4.0.1 release. This release covers general bug fixes on the different implementations, notably C++, R, Python and JavaScript. The list is available here, with the list of contributors here and changelog here. As usual, see the install page for instructions on how to install it.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arrow.apache.org/img/arrow.png" /><media:content medium="image" url="https://arrow.apache.org/img/arrow.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">A New Development Workflow for Arrow’s Rust Implementation</title><link href="https://arrow.apache.org/blog/2021/05/04/rust-dev-workflow/" rel="alternate" type="text/html" title="A New Development Workflow for Arrow’s Rust Implementation" /><published>2021-05-04T00:00:00-04:00</published><updated>2021-05-04T00:00:00-04:00</updated><id>https://arrow.apache.org/blog/2021/05/04/rust-dev-workflow</id><content type="html" xml:base="https://arrow.apache.org/blog/2021/05/04/rust-dev-workflow/">&lt;!--

--&gt;

&lt;p&gt;The Apache Arrow Rust community is excited to announce that its migration to a new development workflow is now complete! If you’re considering Rust as a language for working with columnar data, read on and see how your use case might benefit from our new and improved project setup.&lt;/p&gt;

&lt;p&gt;In recent months, members of the community have been working closely with Arrow’s &lt;a href=&quot;https://arrow.apache.org/committers/&quot;&gt;Project Management Committee&lt;/a&gt; and other contributors to expand the set of available workflows for Arrow implementations. The goal was to define a new development process that ultimately:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Enables a faster release cadence that adheres to &lt;a href=&quot;https://semver.org/&quot;&gt;SemVer&lt;/a&gt; where appropriate&lt;/li&gt;
  &lt;li&gt;Encourages maximum participation from the wider community with unified tooling&lt;/li&gt;
  &lt;li&gt;Ensures that we continue to uphold the tenets of &lt;a href=&quot;https://www.apache.org/theapacheway/&quot;&gt;The Apache Way&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you’re just here for the highlights, the major outcomes of these discussions are as follows:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The Rust projects have moved to separate repositories, outside the main Arrow &lt;a href=&quot;https://en.wikipedia.org/wiki/Monorepo&quot;&gt;monorepo&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/apache/arrow-rs&quot;&gt;arrow-rs&lt;/a&gt; for the core Arrow, Arrow Flight, and Parquet implementations in Rust&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/apache/arrow-datafusion&quot;&gt;arrow-datafusion&lt;/a&gt; for DataFusion and Ballista (more on these projects below!)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The Rust community will use GitHub Issues for tracking feature development and issues, replacing the Jira instance maintained by the Apache Software Foundation (ASF)&lt;/li&gt;
  &lt;li&gt;DataFusion and Ballista will follow a new release cycle, independent of the main Arrow releases&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But why, as a community, have we decided to change our processes? Let’s take a slightly more in-depth look at the Rust implementation’s needs.&lt;/p&gt;

&lt;h2 id=&quot;project-structure&quot;&gt;Project Structure&lt;/h2&gt;
&lt;p&gt;The Rust implementation of Arrow actually consists of several distinct projects, or in Rust parlance, &lt;a href=&quot;https://doc.rust-lang.org/book/ch07-01-packages-and-crates.html&quot;&gt;“crates”&lt;/a&gt;. In addition to the core crates, namely &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arrow&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arrow-flight&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parquet&lt;/code&gt;, we also maintain:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/arrow-datafusion/datafusion&quot;&gt;DataFusion&lt;/a&gt;: an extensible in-memory query execution engine using Arrow as its format&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/arrow-datafusion/ballista&quot;&gt;Ballista&lt;/a&gt;: a distributed compute platform, powered by Apache Arrow and DataFusion&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Whilst these projects are all closely related, with many shared contributors, they’re very much at different stages in their respective lifecycles. The core Arrow crate, as an implementation of a spec, has strict compatibility requirements with other versions of Arrow, and this is tested via rigorous cross-language integration tests.&lt;/p&gt;

&lt;p&gt;However, at the other end of the spectrum, DataFusion and Ballista are still nascent projects in their own right that undergo frequent backwards-incompatible changes. In the old workflow, DataFusion was released in lockstep with Arrow; because DataFusion users often need newly-contributed features or bugfixes on a tighter schedule than Arrow releases, we observed that many people in the community simply resorted to referencing our GitHub repository directly, rather than properly versioned builds on &lt;a href=&quot;https://crates.io/&quot;&gt;crates.io&lt;/a&gt;, Rust’s package registry.&lt;/p&gt;

&lt;p&gt;Ultimately, the decision was made to split the Rust crates into two separate repositories: &lt;a href=&quot;https://github.com/apache/arrow-rs&quot;&gt;arrow-rs&lt;/a&gt; for the core Arrow functionality, and &lt;a href=&quot;https://github.com/apache/arrow-datafusion&quot;&gt;arrow-datafusion&lt;/a&gt; for DataFusion and Ballista. There’s still work to be done on determining the exact release workflows for the latter, but this leaves us in a much better position to meet the broader Rust community’s expectations of crate versioning and stability.&lt;/p&gt;

&lt;h2 id=&quot;community-participation&quot;&gt;Community Participation&lt;/h2&gt;
&lt;p&gt;All Apache projects are built on volunteer contribution; it’s a core principle of both the ASF and open-source software development more broadly. One point of friction that was observed in the previous workflow for the Rust community in particular was the requirement for issues to be logged in Arrow’s Jira project. This step required would-be contributors to first register an account, and then receive a permissions grant to manage tickets.&lt;/p&gt;

&lt;p&gt;To streamline this process for new community members, we’ve taken the decision to migrate to GitHub Issues for tracking both new development work and known bugs that need addressing, and bootstrapped our new repositories by importing their respective tickets from Jira. Creating issues to track non-trivial proposed features and enhancements is still required; this creates an opportunity for community review and helps ensure that feedback is delivered as early in the process as possible. We hope that this strikes a better balance between organization and accessibility for prospective contributors.&lt;/p&gt;

&lt;h2 id=&quot;get-involved&quot;&gt;Get Involved&lt;/h2&gt;
&lt;p&gt;To further improve the onboarding flow for new Arrow contributors, we have started the process of labeling select issues as “good first issue” in &lt;a href=&quot;https://github.com/apache/arrow-rs/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22&quot;&gt;arrow-rs&lt;/a&gt; and &lt;a href=&quot;https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22&quot;&gt;arrow-datafusion&lt;/a&gt;. These issues are small in scope but still serve as valuable contributions to the project, and help new community members to get familiar with our development workflows and tools.&lt;/p&gt;

&lt;p&gt;Not quite sure where to start with a particular issue, or curious about the status of one of our projects? Join the Arrow &lt;a href=&quot;https://arrow.apache.org/community&quot;&gt;mailing lists&lt;/a&gt; or the #arrow-rust channel on the &lt;a href=&quot;https://s.apache.org/slack-invite&quot;&gt;ASF Slack&lt;/a&gt; server.&lt;/p&gt;

&lt;h2 id=&quot;in-closing&quot;&gt;In Closing&lt;/h2&gt;
&lt;p&gt;As a final note: nothing here is intended as prescriptive advice. As a community, we’ve decided that these processes are the best fit for the current status of our projects, but this may change over time! There is, after all, &lt;a href=&quot;https://en.wikipedia.org/wiki/No_Silver_Bullet&quot;&gt;no silver bullet&lt;/a&gt; for software engineering.&lt;/p&gt;</content><author><name>ruanpa</name></author><category term="application" /><summary type="html">The Apache Arrow Rust community is excited to announce that its migration to a new development workflow is now complete! If you’re considering Rust as a language for working with columnar data, read on and see how your use case might benefit from our new and improved project setup. In recent months, members of the community have been working closely with Arrow’s Project Management Committee and other contributors to expand the set of available workflows for Arrow implementations. The goal was to define a new development process that ultimately: Enables a faster release cadence that adheres to SemVer where appropriate Encourages maximum participation from the wider community with unified tooling Ensures that we continue to uphold the tenets of The Apache Way If you’re just here for the highlights, the major outcomes of these discussions are as follows: The Rust projects have moved to separate repositories, outside the main Arrow monorepo arrow-rs for the core Arrow, Arrow Flight, and Parquet implementations in Rust arrow-datafusion for DataFusion and Ballista (more on these projects below!) The Rust community will use GitHub Issues for tracking feature development and issues, replacing the Jira instance maintained by the Apache Software Foundation (ASF) DataFusion and Ballista will follow a new release cycle, independent of the main Arrow releases But why, as a community, have we decided to change our processes? Let’s take a slightly more in-depth look at the Rust implementation’s needs. Project Structure The Rust implementation of Arrow actually consists of several distinct projects, or in Rust parlance, “crates”. In addition to the core crates, namely arrow, arrow-flight, and parquet, we also maintain: DataFusion: an extensible in-memory query execution engine using Arrow as its format Ballista: a distributed compute platform, powered by Apache Arrow and DataFusion Whilst these projects are all closely related, with many shared contributors, they’re very much at different stages in their respective lifecycles. The core Arrow crate, as an implementation of a spec, has strict compatibility requirements with other versions of Arrow, and this is tested via rigorous cross-language integration tests. However, at the other end of the spectrum, DataFusion and Ballista are still nascent projects in their own right that undergo frequent backwards-incompatible changes. In the old workflow, DataFusion was released in lockstep with Arrow; because DataFusion users often need newly-contributed features or bugfixes on a tighter schedule than Arrow releases, we observed that many people in the community simply resorted to referencing our GitHub repository directly, rather than properly versioned builds on crates.io, Rust’s package registry. Ultimately, the decision was made to split the Rust crates into two separate repositories: arrow-rs for the core Arrow functionality, and arrow-datafusion for DataFusion and Ballista. There’s still work to be done on determining the exact release workflows for the latter, but this leaves us in a much better position to meet the broader Rust community’s expectations of crate versioning and stability. Community Participation All Apache projects are built on volunteer contribution; it’s a core principle of both the ASF and open-source software development more broadly. One point of friction that was observed in the previous workflow for the Rust community in particular was the requirement for issues to be logged in Arrow’s Jira project. This step required would-be contributors to first register an account, and then receive a permissions grant to manage tickets. To streamline this process for new community members, we’ve taken the decision to migrate to GitHub Issues for tracking both new development work and known bugs that need addressing, and bootstrapped our new repositories by importing their respective tickets from Jira. Creating issues to track non-trivial proposed features and enhancements is still required; this creates an opportunity for community review and helps ensure that feedback is delivered as early in the process as possible. We hope that this strikes a better balance between organization and accessibility for prospective contributors. Get Involved To further improve the onboarding flow for new Arrow contributors, we have started the process of labeling select issues as “good first issue” in arrow-rs and arrow-datafusion. These issues are small in scope but still serve as valuable contributions to the project, and help new community members to get familiar with our development workflows and tools. Not quite sure where to start with a particular issue, or curious about the status of one of our projects? Join the Arrow mailing lists or the #arrow-rust channel on the ASF Slack server. In Closing As a final note: nothing here is intended as prescriptive advice. As a community, we’ve decided that these processes are the best fit for the current status of our projects, but this may change over time! There is, after all, no silver bullet for software engineering.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arrow.apache.org/img/arrow.png" /><media:content medium="image" url="https://arrow.apache.org/img/arrow.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow 4.0.0 Release</title><link href="https://arrow.apache.org/blog/2021/05/03/4.0.0-release/" rel="alternate" type="text/html" title="Apache Arrow 4.0.0 Release" /><published>2021-05-03T02:00:00-04:00</published><updated>2021-05-03T02:00:00-04:00</updated><id>https://arrow.apache.org/blog/2021/05/03/4.0.0-release</id><content type="html" xml:base="https://arrow.apache.org/blog/2021/05/03/4.0.0-release/">&lt;!--

--&gt;

&lt;p&gt;The Apache Arrow team is pleased to announce the 4.0.0 release. This covers
3 months of development work and includes &lt;a href=&quot;https://issues.apache.org/jira/issues/?jql=project%20%3D%20ARROW%20AND%20status%20%3D%20Resolved%20AND%20fixVersion%20%3D%204.0.0&quot;&gt;&lt;strong&gt;711 resolved issues&lt;/strong&gt;&lt;/a&gt;
from &lt;a href=&quot;/release/4.0.0.html#contributors&quot;&gt;&lt;strong&gt;114 distinct contributors&lt;/strong&gt;&lt;/a&gt;. See the Install Page to learn how to
get the libraries for your platform.&lt;/p&gt;

&lt;p&gt;The release notes below are not exhaustive and only expose selected highlights
of the release. Many other bugfixes and improvements have been made: we refer
you to the &lt;a href=&quot;/release/4.0.0.html&quot;&gt;complete changelog&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;community&quot;&gt;Community&lt;/h2&gt;

&lt;p&gt;Since the 3.0.0 release, Yibo Cai, Ian Cook, and Jonathan Keane
have been invited as committers to Arrow,
and Andrew Lamb and Jorge Leitão have joined the Project Management Committee
(PMC). Thank you for all of your contributions!&lt;/p&gt;

&lt;h2 id=&quot;arrow-flight-rpc-notes&quot;&gt;Arrow Flight RPC notes&lt;/h2&gt;

&lt;p&gt;In Java, applications can now enable zero-copy optimizations when writing
data (ARROW-11066). This potentially breaks source compatibility, so it is
not enabled by default.&lt;/p&gt;

&lt;p&gt;Arrow Flight is now packaged for C#/.NET.&lt;/p&gt;

&lt;h2 id=&quot;linux-packages-notes&quot;&gt;Linux packages notes&lt;/h2&gt;

&lt;p&gt;There are Linux packages for C++ and C GLib. They were provided by Bintray
but &lt;a href=&quot;https://jfrog.com/blog/into-the-sunset-bintray-jcenter-gocenter-and-chartcenter/&quot;&gt;Bintray is no longer available as of 2021-05-01&lt;/a&gt;. They are provided
by Artifactory now. Users needs to change the install instructions because the URL
has changed. See &lt;a href=&quot;/install/&quot;&gt;the install page&lt;/a&gt; for new instructions. Here is a
summary of needed changes.&lt;/p&gt;

&lt;p&gt;For Debian GNU Linux and Ubuntu users:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Users need to change the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;apache-arrow-archive-keyring&lt;/code&gt; install instruction:
    &lt;ul&gt;
      &lt;li&gt;Package name is changed to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;apache-arrow-apt-source&lt;/code&gt;.&lt;/li&gt;
      &lt;li&gt;Download URL is changed to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;https://apache.jfrog.io/artifactory/arrow/...&lt;/code&gt; from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;https://apache.bintray.com/arrow/...&lt;/code&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For CentOS and Red Hat Enterprise Linux users:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Users need to change the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;apache-arrow-release&lt;/code&gt; install instruction:
    &lt;ul&gt;
      &lt;li&gt;Download URL is changed to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;https://apache.jfrog.io/artifactory/arrow/...&lt;/code&gt; from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;https://apache.bintray.com/arrow/...&lt;/code&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;c-notes&quot;&gt;C++ notes&lt;/h2&gt;

&lt;p&gt;The Arrow C++ library now includes a &lt;a href=&quot;https://github.com/apache/arrow/blob/master/cpp/vcpkg.json&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vcpkg.json&lt;/code&gt;&lt;/a&gt;
manifest file and a new CMake option &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-DARROW_DEPENDENCY_SOURCE=VCPKG&lt;/code&gt; to
simplify installation of dependencies using the &lt;a href=&quot;https://github.com/microsoft/vcpkg&quot;&gt;vcpkg&lt;/a&gt;
package manager. This provides an alternative means of installing C++ library
dependencies on Linux, macOS, and Windows. See the
&lt;a href=&quot;/docs/developers/cpp/building.html&quot;&gt;Building Arrow C++&lt;/a&gt;
and &lt;a href=&quot;/docs/developers/cpp/windows.html&quot;&gt;Developing on Windows&lt;/a&gt;
docs pages for details.&lt;/p&gt;

&lt;p&gt;The default memory allocator on macOS has been changed from jemalloc to mimalloc,
yielding performance benefits on a range of macro-benchmarks (ARROW-12316).&lt;/p&gt;

&lt;p&gt;Non-monotonic dense union offsets are now disallowed as per the Arrow format
specification, and return an error in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Array::ValidateFull&lt;/code&gt; (ARROW-10580).&lt;/p&gt;

&lt;h3 id=&quot;compute-layer&quot;&gt;Compute layer&lt;/h3&gt;

&lt;p&gt;Automatic implicit casting in compute kernels (ARROW-8919). For example, for
the addition of two arrays, the arrays are first cast to their common numeric
type instead of erroring when the types are not equal.&lt;/p&gt;

&lt;p&gt;Compute functions &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quantile&lt;/code&gt; (ARROW-10831) and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;power&lt;/code&gt; (ARROW-11070) have been
added for numeric data.&lt;/p&gt;

&lt;p&gt;Compute functions for string processing have been added for:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Trimming characters (ARROW-9128).&lt;/li&gt;
  &lt;li&gt;Extracting substrings captured by a regex pattern (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;extract_regex&lt;/code&gt;, ARROW-10195).&lt;/li&gt;
  &lt;li&gt;Computing UTF8 string lengths (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;utf8_length&lt;/code&gt;, ARROW-11693).&lt;/li&gt;
  &lt;li&gt;Matching strings against regex pattern (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;match_substring_regex&lt;/code&gt;, ARROW-12134).&lt;/li&gt;
  &lt;li&gt;Replacing non-overlapping substrings that match a literal pattern or regular
expression (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replace_substring&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replace_substring_regex&lt;/code&gt;, ARROW-10306).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It is now possible to sort decimal and fixed-width binary data (ARROW-11662).&lt;/p&gt;

&lt;p&gt;The precision of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sum&lt;/code&gt; kernel was improved (ARROW-11758).&lt;/p&gt;

&lt;h3 id=&quot;csv&quot;&gt;CSV&lt;/h3&gt;

&lt;p&gt;A CSV writer has been added (ARROW-2229).&lt;/p&gt;

&lt;p&gt;The CSV reader can now infer timestamp columns with fractional seconds (ARROW-12031).&lt;/p&gt;

&lt;h3 id=&quot;dataset&quot;&gt;Dataset&lt;/h3&gt;

&lt;p&gt;Arrow Datasets received various performance improvements and new
features. Some highlights:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;New columns can be projected from arbitrary expressions at scan time
(ARROW-11174)&lt;/li&gt;
  &lt;li&gt;Read performance was improved for Parquet on high-latency
filesystems (ARROW-11601) and in general when there are thousands of
files or more (ARROW-8658)&lt;/li&gt;
  &lt;li&gt;Null partition keys can be written (ARROW-10438)&lt;/li&gt;
  &lt;li&gt;Compressed CSV files can be read (ARROW-10372)&lt;/li&gt;
  &lt;li&gt;Filesystems support async operations (ARROW-10846)&lt;/li&gt;
  &lt;li&gt;Usage and API documentation were added (ARROW-11677)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;files-and-filesystems&quot;&gt;Files and filesystems&lt;/h3&gt;

&lt;p&gt;Fixed some rare instances of GZip files could not be read properly (ARROW-12169).&lt;/p&gt;

&lt;p&gt;Support for setting S3 proxy parameters has been added (ARROW-8900).&lt;/p&gt;

&lt;p&gt;The HDFS filesystem is now able to write more than 2GB of data at a time
(ARROW-11391).&lt;/p&gt;

&lt;h3 id=&quot;ipc&quot;&gt;IPC&lt;/h3&gt;

&lt;p&gt;The IPC reader now supports reading data with dictionaries shared between
different schema fields (ARROW-11838).&lt;/p&gt;

&lt;p&gt;The IPC reader now supports optional endian conversion when receiving IPC
data represented with a different endianness. It is therefore possible to
exchange Arrow data between systems with different endiannesses (ARROW-8797).&lt;/p&gt;

&lt;p&gt;The IPC file writer now optionally unifies dictionaries when writing a
file in a single shot, instead of erroring out if unequal dictionaries are
encountered (ARROW-10406).&lt;/p&gt;

&lt;p&gt;An interoperability issue with the C# implementation was fixed (ARROW-12100).&lt;/p&gt;

&lt;h3 id=&quot;json&quot;&gt;JSON&lt;/h3&gt;

&lt;p&gt;A possible crash when reading a line-separated JSON file has been fixed (ARROW-12065).&lt;/p&gt;

&lt;h3 id=&quot;orc&quot;&gt;ORC&lt;/h3&gt;

&lt;p&gt;The Arrow C++ library now includes an ORC file writer. Hence it is possible
to both read and write ORC files from/to Arrow data.&lt;/p&gt;

&lt;h3 id=&quot;parquet&quot;&gt;Parquet&lt;/h3&gt;

&lt;p&gt;The Parquet C++ library version is now synced with the Arrow version (ARROW-7830).&lt;/p&gt;

&lt;p&gt;Parquet DECIMAL statistics were previously calculated incorrectly, this
has now been fixed (PARQUET-1655).&lt;/p&gt;

&lt;p&gt;Initial support for high-level Parquet encryption APIs similar to those
in parquet-mr is available (ARROW-9318).&lt;/p&gt;

&lt;h2 id=&quot;c-notes-1&quot;&gt;C# notes&lt;/h2&gt;

&lt;p&gt;Arrow Flight is now packaged for C#/.NET.&lt;/p&gt;

&lt;h2 id=&quot;go-notes&quot;&gt;Go notes&lt;/h2&gt;

&lt;p&gt;The go implementation now supports IPC buffer compression&lt;/p&gt;

&lt;h2 id=&quot;java-notes&quot;&gt;Java notes&lt;/h2&gt;

&lt;p&gt;Java now supports IPC buffer compression (ZSTD is recommended as the current performance of LZ4 is quite slow).&lt;/p&gt;

&lt;h2 id=&quot;javascript-notes&quot;&gt;JavaScript notes&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;The Arrow JS module is now tree-shakeable.&lt;/li&gt;
  &lt;li&gt;Iterating over Tables or Vectors is ~2X faster. &lt;a href=&quot;https://observablehq.com/@domoritz/arrow-js-3-vs-4-iterator&quot;&gt;Demo&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;The default bundles use modern JS.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;python-notes&quot;&gt;Python notes&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Limited support for writing out CSV files (only types that have cast implementation to String) is now available.&lt;/li&gt;
  &lt;li&gt;Writing parquet list types now has the option of enabling the canonical group naming according to the Parquet specification.&lt;/li&gt;
  &lt;li&gt;The ORC Writer is now available.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Creating a dataset with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pyarrow.dataset.write_dataset&lt;/code&gt; is now possible from a
Python iterator of record batches (ARROW-10882).
The Dataset interface can now use custom projections using expressions when
scanning (ARROW-11750). The expressions gained basic support for arithmetic
operations (e.g. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ds.field(&apos;a&apos;) / ds.field(&apos;b&apos;)&lt;/code&gt;) (ARROW-12058). See
the &lt;a href=&quot;https://arrow.apache.org/docs/python/dataset.html#projecting-columns&quot;&gt;Dataset docs&lt;/a&gt; for more details.&lt;/p&gt;

&lt;p&gt;See the C++ notes above for additional details.&lt;/p&gt;

&lt;h2 id=&quot;r-notes&quot;&gt;R notes&lt;/h2&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dplyr&lt;/code&gt; interface to Arrow data gained many new features in this release, including support for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mutate()&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;relocate()&lt;/code&gt;, and more. You can also call in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filter()&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mutate()&lt;/code&gt; over 100 functions supported by the Arrow C++ library, and many string functions are available both by their base R (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grepl()&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gsub()&lt;/code&gt;, etc.) and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;stringr&lt;/code&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;str_detect()&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;str_replace()&lt;/code&gt;) spellings.&lt;/p&gt;

&lt;p&gt;Datasets can now read compressed CSVs automatically, and you can also open a dataset that is based on a single file, enabling you to use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;write_dataset()&lt;/code&gt; to partition a very large file without having to read the whole file into memory.&lt;/p&gt;

&lt;p&gt;For more on what’s in the 4.0.0 R package, see the &lt;a href=&quot;/docs/r/news/&quot;&gt;R changelog&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;c-glib-and-ruby-notes&quot;&gt;C GLib and Ruby notes&lt;/h2&gt;

&lt;h3 id=&quot;c-glib&quot;&gt;C GLib&lt;/h3&gt;

&lt;p&gt;In Arrow GLib version 4.0.0, the following changes are introduced in addition to the changes by Arrow C++.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;gandiva-glib supports filtering by using the newly introduced &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GGandivaFilter&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GGandivaCondition&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GGandivaSelectableProjector&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;input&lt;/code&gt; property is added in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GArrowCSVReader&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GArrowJSONReader&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;GNU Autotools, namely &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;configure&lt;/code&gt; script, support is dropped&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GADScanContext&lt;/code&gt; is removed, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;use_threads&lt;/code&gt; property is moved to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GADScanOptions&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;garrow_chunked_array_combine&lt;/code&gt; function is added&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;garrow_array_concatenate&lt;/code&gt; function is added&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GADFragment&lt;/code&gt; and its subclass &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GADInMemoryFragment&lt;/code&gt; are added&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GADScanTask&lt;/code&gt; now holds the corresponding &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GADFragment&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gad_scan_options_replace_schema&lt;/code&gt; function is removed&lt;/li&gt;
  &lt;li&gt;The name of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Decimal128DataType&lt;/code&gt; is changed to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;decimal128&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ruby&quot;&gt;Ruby&lt;/h3&gt;

&lt;p&gt;In Red Arrow version 4.0.0, the following changes are introduced in addition to the changes by Arrow GLib.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ArrowDataset::ScanContext&lt;/code&gt; is removed, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;use_threads&lt;/code&gt; attribute is moved to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ArrowDataset::ScanOptions&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Arrow::Array#concatenate&lt;/code&gt; is added; it can concatenate not only an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Arrow::Array&lt;/code&gt; but also a normal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Array&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Arrow::SortKey&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Arrow::SortOptions&lt;/code&gt; are added for accepting Ruby objects as sort key and options&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ArrowDataset::InMemoryFragment&lt;/code&gt; is added&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;rust-notes&quot;&gt;Rust notes&lt;/h2&gt;

&lt;p&gt;This release of Arrow continues to add new features and performance improvements. Much of our time this release was spent hammering out the necessary details so we can release the Rust versions to cargo at a more regular rate. In addition, we welcomed the &lt;a href=&quot;https://ballistacompute.org/&quot;&gt;Ballista distributed compute project&lt;/a&gt; officially to the fold.&lt;/p&gt;

&lt;h3 id=&quot;arrow&quot;&gt;Arrow&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Improved LargeUtf8 support&lt;/li&gt;
  &lt;li&gt;Improved null handling in AND/OR kernels&lt;/li&gt;
  &lt;li&gt;Added JSON writer support (ARROW-11310)&lt;/li&gt;
  &lt;li&gt;JSON reader improvements&lt;/li&gt;
  &lt;li&gt;LargeUTF8
    &lt;ul&gt;
      &lt;li&gt;Improved schema inference for nested list and struct types&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Various performance improvements&lt;/li&gt;
  &lt;li&gt;IPC writer no longer calls finish() implicitly on drop&lt;/li&gt;
  &lt;li&gt;Compute kernels
    &lt;ul&gt;
      &lt;li&gt;Support for optional &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;limit&lt;/code&gt; in sort kernel&lt;/li&gt;
      &lt;li&gt;Divide by a single scalar&lt;/li&gt;
      &lt;li&gt;Support for casting to timestamps&lt;/li&gt;
      &lt;li&gt;Cast: Improved support between casting List, LargeList, Int32, Int64, Date64&lt;/li&gt;
      &lt;li&gt;Kernel to combine two arrays based on boolean mask&lt;/li&gt;
      &lt;li&gt;Pow kernel&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;new_null_array&lt;/code&gt; for creating Arrays full of nulls.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;parquet-1&quot;&gt;Parquet&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Added support for filtering row groups (used by DataFusion to implement filter push-down)&lt;/li&gt;
  &lt;li&gt;Added support for Parquet v 2.0 logical types&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;datafusion&quot;&gt;DataFusion&lt;/h3&gt;

&lt;p&gt;New Features&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;SQL Support&lt;/li&gt;
  &lt;li&gt;
    &lt;ul&gt;
      &lt;li&gt;CTEs&lt;/li&gt;
      &lt;li&gt;UNION&lt;/li&gt;
      &lt;li&gt;HAVING&lt;/li&gt;
      &lt;li&gt;EXTRACT&lt;/li&gt;
      &lt;li&gt;SHOW TABLES&lt;/li&gt;
      &lt;li&gt;SHOW COLUMNS&lt;/li&gt;
      &lt;li&gt;INTERVAL&lt;/li&gt;
      &lt;li&gt;SQL Information schema&lt;/li&gt;
      &lt;li&gt;Support GROUP BY for more data types, including dictionary columns, boolean, Date32&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Extensibility API
    &lt;ul&gt;
      &lt;li&gt;Catalogs and schemas support&lt;/li&gt;
      &lt;li&gt;Table deregistration&lt;/li&gt;
      &lt;li&gt;Better support for multiple optimizers&lt;/li&gt;
      &lt;li&gt;User defined functions can now provide specialized implementations for scalar values&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Physical Plans&lt;/li&gt;
  &lt;li&gt;Hash Repartitioning&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;SQL Metrics&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Additional Postgres compatible function library:
    &lt;ul&gt;
      &lt;li&gt;Length functions&lt;/li&gt;
      &lt;li&gt;Pad/trim functions&lt;/li&gt;
      &lt;li&gt;Concat functions&lt;/li&gt;
      &lt;li&gt;Ascii/Unicode functions&lt;/li&gt;
      &lt;li&gt;Regex&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Proper identifier case identification (e.g. “Foo” vs Foo vs foo)&lt;/li&gt;
  &lt;li&gt;Upgraded to Tokio 1.x&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Performance Improvements:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;LIMIT pushdown&lt;/li&gt;
  &lt;li&gt;Constant folding&lt;/li&gt;
  &lt;li&gt;Partitioned hash join&lt;/li&gt;
  &lt;li&gt;Create hashes vectorized in hash join&lt;/li&gt;
  &lt;li&gt;Improve parallelism using repartitioning pass&lt;/li&gt;
  &lt;li&gt;Improved hash aggregate performance with large number of grouping values&lt;/li&gt;
  &lt;li&gt;Predicate pushdown support for table scans&lt;/li&gt;
  &lt;li&gt;Predicate push-down to parquet enables DataFusion to quickly eliminate entire parquet row-groups based on query filter expressions and parquet row group min/max statistics&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;API Changes&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;DataFrame methods now take &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Vec&amp;lt;Expr&amp;gt;&lt;/code&gt; rather than &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;amp;[Expr]&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;TableProvider now consistently uses &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Arc&amp;lt;TableProvider&amp;gt;&lt;/code&gt; rather than &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Box&amp;lt;TableProvider&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ballista&quot;&gt;Ballista&lt;/h3&gt;

&lt;p&gt;Ballista was donated shortly before the Arrow 4.0.0 release and there is no new release of Ballista as part of Arrow 4.0.0&lt;/p&gt;</content><author><name>pmc</name></author><category term="release" /><summary type="html">The Apache Arrow team is pleased to announce the 4.0.0 release. This covers 3 months of development work and includes 711 resolved issues from 114 distinct contributors. See the Install Page to learn how to get the libraries for your platform. The release notes below are not exhaustive and only expose selected highlights of the release. Many other bugfixes and improvements have been made: we refer you to the complete changelog. Community Since the 3.0.0 release, Yibo Cai, Ian Cook, and Jonathan Keane have been invited as committers to Arrow, and Andrew Lamb and Jorge Leitão have joined the Project Management Committee (PMC). Thank you for all of your contributions! Arrow Flight RPC notes In Java, applications can now enable zero-copy optimizations when writing data (ARROW-11066). This potentially breaks source compatibility, so it is not enabled by default. Arrow Flight is now packaged for C#/.NET. Linux packages notes There are Linux packages for C++ and C GLib. They were provided by Bintray but Bintray is no longer available as of 2021-05-01. They are provided by Artifactory now. Users needs to change the install instructions because the URL has changed. See the install page for new instructions. Here is a summary of needed changes. For Debian GNU Linux and Ubuntu users: Users need to change the apache-arrow-archive-keyring install instruction: Package name is changed to apache-arrow-apt-source. Download URL is changed to https://apache.jfrog.io/artifactory/arrow/... from https://apache.bintray.com/arrow/.... For CentOS and Red Hat Enterprise Linux users: Users need to change the apache-arrow-release install instruction: Download URL is changed to https://apache.jfrog.io/artifactory/arrow/... from https://apache.bintray.com/arrow/.... C++ notes The Arrow C++ library now includes a vcpkg.json manifest file and a new CMake option -DARROW_DEPENDENCY_SOURCE=VCPKG to simplify installation of dependencies using the vcpkg package manager. This provides an alternative means of installing C++ library dependencies on Linux, macOS, and Windows. See the Building Arrow C++ and Developing on Windows docs pages for details. The default memory allocator on macOS has been changed from jemalloc to mimalloc, yielding performance benefits on a range of macro-benchmarks (ARROW-12316). Non-monotonic dense union offsets are now disallowed as per the Arrow format specification, and return an error in Array::ValidateFull (ARROW-10580). Compute layer Automatic implicit casting in compute kernels (ARROW-8919). For example, for the addition of two arrays, the arrays are first cast to their common numeric type instead of erroring when the types are not equal. Compute functions quantile (ARROW-10831) and power (ARROW-11070) have been added for numeric data. Compute functions for string processing have been added for: Trimming characters (ARROW-9128). Extracting substrings captured by a regex pattern (extract_regex, ARROW-10195). Computing UTF8 string lengths (utf8_length, ARROW-11693). Matching strings against regex pattern (match_substring_regex, ARROW-12134). Replacing non-overlapping substrings that match a literal pattern or regular expression (replace_substring and replace_substring_regex, ARROW-10306). It is now possible to sort decimal and fixed-width binary data (ARROW-11662). The precision of the sum kernel was improved (ARROW-11758). CSV A CSV writer has been added (ARROW-2229). The CSV reader can now infer timestamp columns with fractional seconds (ARROW-12031). Dataset Arrow Datasets received various performance improvements and new features. Some highlights: New columns can be projected from arbitrary expressions at scan time (ARROW-11174) Read performance was improved for Parquet on high-latency filesystems (ARROW-11601) and in general when there are thousands of files or more (ARROW-8658) Null partition keys can be written (ARROW-10438) Compressed CSV files can be read (ARROW-10372) Filesystems support async operations (ARROW-10846) Usage and API documentation were added (ARROW-11677) Files and filesystems Fixed some rare instances of GZip files could not be read properly (ARROW-12169). Support for setting S3 proxy parameters has been added (ARROW-8900). The HDFS filesystem is now able to write more than 2GB of data at a time (ARROW-11391). IPC The IPC reader now supports reading data with dictionaries shared between different schema fields (ARROW-11838). The IPC reader now supports optional endian conversion when receiving IPC data represented with a different endianness. It is therefore possible to exchange Arrow data between systems with different endiannesses (ARROW-8797). The IPC file writer now optionally unifies dictionaries when writing a file in a single shot, instead of erroring out if unequal dictionaries are encountered (ARROW-10406). An interoperability issue with the C# implementation was fixed (ARROW-12100). JSON A possible crash when reading a line-separated JSON file has been fixed (ARROW-12065). ORC The Arrow C++ library now includes an ORC file writer. Hence it is possible to both read and write ORC files from/to Arrow data. Parquet The Parquet C++ library version is now synced with the Arrow version (ARROW-7830). Parquet DECIMAL statistics were previously calculated incorrectly, this has now been fixed (PARQUET-1655). Initial support for high-level Parquet encryption APIs similar to those in parquet-mr is available (ARROW-9318). C# notes Arrow Flight is now packaged for C#/.NET. Go notes The go implementation now supports IPC buffer compression Java notes Java now supports IPC buffer compression (ZSTD is recommended as the current performance of LZ4 is quite slow). JavaScript notes The Arrow JS module is now tree-shakeable. Iterating over Tables or Vectors is ~2X faster. Demo The default bundles use modern JS. Python notes Limited support for writing out CSV files (only types that have cast implementation to String) is now available. Writing parquet list types now has the option of enabling the canonical group naming according to the Parquet specification. The ORC Writer is now available. Creating a dataset with pyarrow.dataset.write_dataset is now possible from a Python iterator of record batches (ARROW-10882). The Dataset interface can now use custom projections using expressions when scanning (ARROW-11750). The expressions gained basic support for arithmetic operations (e.g. ds.field(&apos;a&apos;) / ds.field(&apos;b&apos;)) (ARROW-12058). See the Dataset docs for more details. See the C++ notes above for additional details. R notes The dplyr interface to Arrow data gained many new features in this release, including support for mutate(), relocate(), and more. You can also call in filter() or mutate() over 100 functions supported by the Arrow C++ library, and many string functions are available both by their base R (grepl(), gsub(), etc.) and stringr (str_detect(), str_replace()) spellings. Datasets can now read compressed CSVs automatically, and you can also open a dataset that is based on a single file, enabling you to use write_dataset() to partition a very large file without having to read the whole file into memory. For more on what’s in the 4.0.0 R package, see the R changelog. C GLib and Ruby notes C GLib In Arrow GLib version 4.0.0, the following changes are introduced in addition to the changes by Arrow C++. gandiva-glib supports filtering by using the newly introduced GGandivaFilter, GGandivaCondition, and GGandivaSelectableProjector The input property is added in GArrowCSVReader and GArrowJSONReader GNU Autotools, namely configure script, support is dropped GADScanContext is removed, and use_threads property is moved to GADScanOptions garrow_chunked_array_combine function is added garrow_array_concatenate function is added GADFragment and its subclass GADInMemoryFragment are added GADScanTask now holds the corresponding GADFragment gad_scan_options_replace_schema function is removed The name of Decimal128DataType is changed to decimal128 Ruby In Red Arrow version 4.0.0, the following changes are introduced in addition to the changes by Arrow GLib. ArrowDataset::ScanContext is removed, and use_threads attribute is moved to ArrowDataset::ScanOptions Arrow::Array#concatenate is added; it can concatenate not only an Arrow::Array but also a normal Array Arrow::SortKey and Arrow::SortOptions are added for accepting Ruby objects as sort key and options ArrowDataset::InMemoryFragment is added Rust notes This release of Arrow continues to add new features and performance improvements. Much of our time this release was spent hammering out the necessary details so we can release the Rust versions to cargo at a more regular rate. In addition, we welcomed the Ballista distributed compute project officially to the fold. Arrow Improved LargeUtf8 support Improved null handling in AND/OR kernels Added JSON writer support (ARROW-11310) JSON reader improvements LargeUTF8 Improved schema inference for nested list and struct types Various performance improvements IPC writer no longer calls finish() implicitly on drop Compute kernels Support for optional limit in sort kernel Divide by a single scalar Support for casting to timestamps Cast: Improved support between casting List, LargeList, Int32, Int64, Date64 Kernel to combine two arrays based on boolean mask Pow kernel new_null_array for creating Arrays full of nulls. Parquet Added support for filtering row groups (used by DataFusion to implement filter push-down) Added support for Parquet v 2.0 logical types DataFusion New Features SQL Support CTEs UNION HAVING EXTRACT SHOW TABLES SHOW COLUMNS INTERVAL SQL Information schema Support GROUP BY for more data types, including dictionary columns, boolean, Date32 Extensibility API Catalogs and schemas support Table deregistration Better support for multiple optimizers User defined functions can now provide specialized implementations for scalar values Physical Plans Hash Repartitioning SQL Metrics Additional Postgres compatible function library: Length functions Pad/trim functions Concat functions Ascii/Unicode functions Regex Proper identifier case identification (e.g. “Foo” vs Foo vs foo) Upgraded to Tokio 1.x Performance Improvements: LIMIT pushdown Constant folding Partitioned hash join Create hashes vectorized in hash join Improve parallelism using repartitioning pass Improved hash aggregate performance with large number of grouping values Predicate pushdown support for table scans Predicate push-down to parquet enables DataFusion to quickly eliminate entire parquet row-groups based on query filter expressions and parquet row group min/max statistics API Changes DataFrame methods now take Vec&amp;lt;Expr&amp;gt; rather than &amp;amp;[Expr] TableProvider now consistently uses Arc&amp;lt;TableProvider&amp;gt; rather than Box&amp;lt;TableProvider&amp;gt; Ballista Ballista was donated shortly before the Arrow 4.0.0 release and there is no new release of Ballista as part of Arrow 4.0.0</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arrow.apache.org/img/arrow.png" /><media:content medium="image" url="https://arrow.apache.org/img/arrow.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>